{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code.ipynb\n",
      "time_series.ipynb\n",
      "COMMIT_EDITMSG\n",
      "config\n",
      "description\n",
      "HEAD\n",
      "index\n",
      "applypatch-msg.sample\n",
      "commit-msg.sample\n",
      "fsmonitor-watchman.sample\n",
      "post-update.sample\n",
      "pre-applypatch.sample\n",
      "pre-commit.sample\n",
      "pre-push.sample\n",
      "pre-rebase.sample\n",
      "pre-receive.sample\n",
      "prepare-commit-msg.sample\n",
      "update.sample\n",
      "exclude\n",
      "HEAD\n",
      "master\n",
      "master\n",
      "f1b70eed8c0f58883c67ae94393f5912538e83\n",
      "87365763a6699abeb78e36b29599108e065542\n",
      "7665ed2976863334253b076b8b870355dfd30e\n",
      "8238ea02b1095a2e9f6f7466d17e37a4009604\n",
      "008e38e53173d537c97cd7f0f4c9095cc2c920\n",
      "5a164683dab14a2c38acea119d67b93896b80a\n",
      "f61801577291fe904e21dc0010267661f72f3d\n",
      "42a29f266ab659e685cef3802de3af0e1b61c7\n",
      "691f6c8009de7e94a6f15970341f7db3d50f5d\n",
      "90eeb31c5e8b9757d1c386fba0290f5550a017\n",
      "8a1b4139c3977dfd8d9b5554209bbd4b960b64\n",
      "d781a6be05422435310e54dced2d78362b6282\n",
      "137e7438a9e3f19bb4ba053aca28869d87b62e\n",
      "872ad8190c605e1d9fc59f28d1f79ae53d89f8\n",
      "487abd3cf5acf3cec604d7554e3129c0d1440e\n",
      "a33ca8eed5e64a40f3eba250a9456699bc62a0\n",
      "2c3fa9c30219a21d44f0edee15e2fc891cfee6\n",
      "381bfa563cb65d2ec3985e03ebaa2359e10a71\n",
      "9864d8ecfa50c20ab18f5b85d01278e59e7f0b\n",
      "fbafeb45ca9272002d3b1a5f2d1f4a6f2986c3\n",
      "9b9abc076d04cc59e358ec48820590ca5b41b0\n",
      "0b8f593c426b13ec90254505b98c28f9c30faa\n",
      "30de484fef1ecf25afffc168ba3db93f4d7b1a\n",
      "0e7715444b11614880d75fb950157c49984965\n",
      "7966a852438b19a601f1ab37744021ba688c95\n",
      "e6a3cedcfc4d8b4ae46d7252c3860a384c6396\n",
      "f61165436d7d881b6499069637301903f0819f\n",
      "1c9ec4aace5f94706064b69d1d311cbdb67b59\n",
      "00ef74bde791d30278d2b5a92735b384c12a8f\n",
      "1513c0511644910cbc26c17a28a8c879bce210\n",
      "5b3085f2e9829934c4a12c334426119a375377\n",
      "9cb837d9f74bcd2e744dd88d3bafe9d83f53d6\n",
      "d4f6ae34875e0809a95090c554d18c50bfa100\n",
      "d3162143e53c62860170758f1064bfe9856fbd\n",
      "e364fc360251f6fdb057a88808af40170e8de3\n",
      "58da3ef27f5c53b7e0121cb4cbf29018c821b3\n",
      "0f0cf6de729ddf1014774970b72162588a6abb\n",
      "16b12baa8b1a948a9e67981adb0454669ad9d7\n",
      "d6e8e741f9b1326233fc1ec14e978bce16d530\n",
      "666c30c1bf494e6cc5450522b02b91518ff2a2\n",
      "aae65cbb38481bb2bbcfb9a366509f341e5415\n",
      "c6a4e8bcce38c5582b8a62785a2db48289479f\n",
      "5a9ef48e968702bd05910934e88288ee4d966f\n",
      "0614393d2777410e9035f7aedccda203584bc8\n",
      "967ef0de14c7d040a2c150380ff4720f081a0a\n",
      "55b785dc52d53616fbd3f17be816520d8d63c6\n",
      "6fc1ae2dad946024d09476d9a106472158e049\n",
      "5b75490a4d94046231c610dfe8c7912d1b8237\n",
      "9115bb7d49de6330c811a982d1faac57bcfc8e\n",
      "0c13509ebdfd00550a34a7c43e35589bff88e0\n",
      "75eacc1ccd1644ac81f05800c9dec1dc852166\n",
      "78d816d46c655b7142c6c4c7ac525cba2a9c14\n",
      "f31256367ed010850554c6109946584c693441\n",
      "b5e69851e90af393d1271667a8f4361f42dab6\n",
      "1d5d8d9304229efa6337e6be4a0eb5b9c59e94\n",
      "0ffe61d871b78998937c8cf716d396e422b0b7\n",
      "b6d67bfa173d5fe4d1b5c3dcad5ca26d0273cb\n",
      "d746d04ada0c87965f2044228c09e200d60937\n",
      "f6127501feb99df99e75b64c5b83f5ae42aae8\n",
      "4645f6dd6cba033c4fcbaf63df052eab96542a\n",
      "42140789af50e5fbbc8110153968c054be5c2b\n",
      "8e100c54b0c6aca16191273f73f046c8d2d35f\n",
      "fddb093156574da51ac66e4e76b8d74cb96d5e\n",
      "4490f13d13f6fdb5e3d4a25cf4bd1035fa9f78\n",
      "e2555562d80e113666be5597bb5d7806e167ce\n",
      "b0cff761b9989e2de570bd784bfdfef3256bad\n",
      "e761df34c826e351540b6b4fb36881f0b12b9d\n",
      "9ad61d68ee1230d185ac79994d643f9d7357ae\n",
      "b1cfa9eb24ed1bd3681f133c3b13109db1b7e4\n",
      "c38690e1b9e81d90e5cb6d2eebb10db705bfa3\n",
      "08050600ace44758b5650c2981e41f0f11fa27\n",
      "7a71c3f693b93b0991f37be50f7f90f52f264b\n",
      "41e994ba01fd5170fa38b6c87b26124ab9656d\n",
      "5ba838c13c53c99249565c77cdc5ec69ee0acf\n",
      "c51711f754fd131e77777e5deefe7eccecf64b\n",
      "3aba763c4b3fb18edd006c2e6a9e19bf8dbfa8\n",
      "2bce63d7123688016e01de92ca7cd492cb34ab\n",
      "379defd1bc9cbddf6b9110394b32e1a912be0d\n",
      "fa8e832de1cf56d077ea9e40ac1ed3aa4d94c8\n",
      "10e80bdaed7ceb286d2bf5ca433d9cbcad753a\n",
      "598c7af077833ea311342ff16d411b9cc638a2\n",
      "bd60313b0e77495c3602efaa86dc01243b56a1\n",
      "119095b64cb9093973e7947d24cababff969d4\n",
      "6143e6d9b9d46f655b43659346aca256eea221\n",
      "8623e113812413cf2f5f06a14732899a4c6611\n",
      "ef02ada3fdf506efd6495b96f63f58745785b1\n",
      "050987b8693254cca316f9e3b605c6b8e27a0a\n",
      "5bcf34e3cc097f869a9ac3c62a402ced134f8c\n",
      "a4690788f551e630d1aa1b56e3dfefaba6bcfc\n",
      "c15218ddb7a4c45bf567192c087d95c08d15f1\n",
      "12a97d4196a83f1ced852b98744ee0e67a54c1\n",
      "35108143b2f78a0fbaa38b99ff20be5f475f96\n",
      "bf27328983db739f8c20d3820b4035a3e0282a\n",
      "fceb13ceee962b2a5ec4c2d2b7a2923cb7ae11\n",
      "126947072b45da7a0d020b49441626e3c4bd2a\n",
      "29cf6db3707a9cfc5f2264974b9cdcd7e9fa23\n",
      "185fac63316a02d1075c6130306b0c92ba1001\n",
      "2213985f3889c4c09b3b7a4b6f0eaa23ad7140\n",
      "f002c2f6f22f66eab82c669b365efd8ca83ab0\n",
      "0bd93c3933d77a125eed9d2c2b45fe6f28b1ac\n",
      "f339c136e88951f816241dcc2fdc052c8b527d\n",
      "eb2f54e415bb59ff735fb4effab9d0dd31327f\n",
      "f89b3d0174eb6727dde2f4a2ed04ad18c47d12\n",
      "4ed75d7f528a5a23fc9ddaa93553b1b52ea651\n",
      "e353636ec656818779924b030f92830d6e1939\n",
      "2a21f6e1ed06cbe3ff1a878c7e21d1ca64d29c\n",
      "ca5e76cac8c561e2499e0b084c080d568dab04\n",
      "e1ff89824ea63696796d5925a5a0677cca6fe5\n",
      "b9e9cfd5a5fc68e904f1440f01423b14327a36\n",
      "37b176e43961565a217f6dcb228ff941ba6363\n",
      "7238115aec3252ce4a193235b05417544bf7c3\n",
      "7b5e6293d06e483db9817ea37935cbb41a6687\n",
      "fd063111288e9b0cb204d0de03f1fd4680b283\n",
      "509ba404dda6383a4154fe10c3bb37e571213b\n",
      "f4a73fab1a6c7691ee40d45f6c3c2052965881\n",
      "299b36ca433885bc61e955de51fcebe915fd6e\n",
      "6ef4c104be4d4d31c2016d5ddeac30ebe122d0\n",
      "fe52cd11dc2a02996fc15d20af890940393315\n",
      "11de73113b678c7712df4f698fd9de0d9f2b31\n",
      "744585375268ac8a7b3e4244164a0f70ee58d1\n",
      "cea7666b69b484d134e33cdd82c2f2d4633b9f\n",
      "56265589ef6f02bf3484a4be13fd09fa69b1e4\n",
      "2c6062c86c96c89d9155edb1e10af4e39e98fd\n",
      "b529e88514fc8bfaf39f401c535d6f220b92f8\n",
      "944272a2f8f85b991ce3b6c161df22ec025bf5\n",
      "faa191905a113b6142d9260f573e1a881554bd\n",
      "9fa905c2f9b658b23747f5c0959c4898eb8482\n",
      "8f3256cbb4e2ece0b9ee09d1d58d34a8a44c17\n",
      "fa09a9fa4f42966a30403e85d1ff4c682ad3a7\n",
      "470fee9636099939e73ea70db56fcf7e1b17f3\n",
      "7060d3ce0af45ed1ee29cc7df51e47babe3723\n",
      "cc84ccce88ef90b57358ceb1779784e24e25bb\n",
      "2d97eb83e867678a3fd67d769e7d27382d4bcd\n",
      "f0b5d2d57856afd8393b8190c81b4a47a7861a\n",
      "bf70288f678a74f95d3eec3d7adffe37c616e8\n",
      "17389de035db2eafd0caed4851fdfe718a46a1\n",
      "3b5939883a0b4d30133d941169f404d04de77f\n",
      "fcb717d539e250370df33e66773781fdf57e07\n",
      "a69a4b334cc539f34df2853bc52b06198a5484\n",
      "bdf1a4805a4b40770e50a8484ed9555684972f\n",
      "ec8cf73fe914c91736e2b2d46f4eaadceaadca\n",
      "0a7f51ce25f9686ede56b867a436c96f0cf080\n",
      "2b339a7baa1853d5f1555666a9df3917224ed0\n",
      "d3ca0a7e686a06be9ee69cff6ca58638505f6a\n",
      "b632c115619bed78a8a14794302b51bcae3af1\n",
      "8210e30e5d8c53eb2d2bebd7249c313432f1c8\n",
      "9b949611cb1ce22d991712e523d7f79fb6f57e\n",
      "ceebca4769d4070d30f94b7c9b3924b6b4cf0b\n",
      "6c592733c3ed1059df9cbac0e89960f421f8a0\n",
      "e2eee41297f5b1d579c7a130c8dff307c0e952\n",
      "182ecba3a51f70b3c5373b6e032b5360a2b712\n",
      "5dc4897c09cc054a785dea777eece8860d7c73\n",
      "309d3682867fc0a61880484773e8b4b70e828f\n",
      "79fc63bb6aba0f2aa92e365e5eb69e5a42be21\n",
      "62f27e87e28de0bea1b768258ee0616bfd83a6\n",
      "5b10491c758de1b2d68fcd21176b6a5a3af025\n",
      "c916b466adc42a9acbde7512b9e011b6a1929c\n",
      "4b081087ccd0ca11ce2d6807bd068fa304735b\n",
      "7927e0130d1316459b5de6daf26e451c80caee\n",
      "d628632721f5d2b84b6023db43ac966b75c999\n",
      "364c3a58d0da75deed1d36ce7463d1bba84315\n",
      "e1da415703ac37748cd85f257d5d1378e00cae\n",
      "3745347f1d6e8b7f4f8c46a5ca62c102fe742f\n",
      "db6c18b79c5a9f2d3a9ae6df60d955d4699c54\n",
      "cbcbc5ce1d7c3f20ac57552960529ab11821d3\n",
      "d16d8c60dd65c2901a614c0dc0e50f58c021e7\n",
      "d9b63096161fa7959729a485963fd5bbebb693\n",
      "07b0ed122a22940ac109907b311d1e78117060\n",
      "7f5f9a4a59b85a399c178336be40191f348149\n",
      "e30b75da2316f6f88fac1a8d75c5cb4cf0dfd7\n",
      "18a91337e47569119909c62d6d496bcf12b8ea\n",
      "5a2658241f4d6a05d08f2197465c87ca83c336\n",
      "25475189fda3260d604fe07042c5a75c3ab784\n",
      "331f882aad80516b9695ae5ef756abd4c9e647\n",
      "cd63c354c16910055a179d959ac83d961b80e1\n",
      "be7780d2f2e7925b1b6daff568f790aef86f12\n",
      "61570ac66f24cc0051219c81753c9261af209b\n",
      "382c9522dbddadb2f82805b23bd5d1ec86fbda\n",
      "9c0de5b5083c05d97526251529ea0a5d79cc6f\n",
      "b7baecb92de7b3c546a75995280deab472beda\n",
      "52db54cef94fa29e91b2ec116d600d90f7526c\n",
      "0bc3cadd5a87a6ccba39fb40b9eb58263c13f1\n",
      "0277e7ddf62ab6de93b31b360c75d999ee67d9\n",
      "9248ea44239cd82efe9e5b7523b75894c5a4ac\n",
      "f601fe2762e8642c291f6114dbc9676f671827\n",
      "a98f26dc0c8ef8e012214e39de1f35c4759f5e\n",
      "b5b8b0723922db3aa7c1719aed85cab51a12ce\n",
      "03875cc4d7c54ed14a2a5b55d3d2a07097f80e\n",
      "f0b3456e408c3a8725a99604e725f9eb31f6de\n",
      "4a631d848e44f256345d2e1bde18ba65aa6be8\n",
      "a23661958f8590fd5124b7357ed4cb3adaf479\n",
      "02cc4afdaf64024d02e56b19b78cc601b85a3e\n",
      "200f2686f8731e80f073b0bfe87a653c67154a\n",
      "master\n",
      "master\n",
      "code-checkpoint.ipynb\n",
      "time_series-checkpoint.ipynb\n",
      "2015OnLineCustHist.csv\n",
      "2015OnLineCustHist.xlsx\n",
      "control_chart.csv\n",
      "control_chart.png\n",
      "dataset_Facebook.csv\n",
      "dataset_Facebook_v2.csv\n",
      "energydata_complete.csv\n",
      "forecast.csv\n",
      "predictions.csv\n",
      "predictions_exer.csv\n",
      "time_series.png\n",
      "time_series_m.png\n"
     ]
    }
   ],
   "source": [
    "#Imnporting libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_slsqp\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "import math\n",
    "import scipy\n",
    "import scipy.stats as stats\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model\n",
    "import Tkinter as tk\n",
    "import statsmodels.api as sm\n",
    "from pyvttbl import DataFrame\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "#Listing the existing files in the dir\n",
    "for root, dirs, files in os.walk(\".\"):  \n",
    "    for filename in files:\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataset\n",
    "arr = [ 25, 48, 37, 41, 19, 32, 26, 16, 23, 23, 29, 36, 31, 26, 21, 32, 25, 31, 43, 35, 42, 38, 33, 28]\n",
    "df = pd.DataFrame(arr)\n",
    "df.columns = ['Values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating the number of classses following the formula that 2 ** k > n\n",
    "N = int(round(math.log(len(df['Values']), 2)))\n",
    "\n",
    "#Calculating class width\n",
    "intervals = ((df['Values'].max() - df['Values'].min()) / N).round(decimals = 0)\n",
    "limits = []\n",
    "limits.append(df['Values'].min() + intervals)\n",
    "\n",
    "def classes(N):\n",
    "    '''The function defines the lower limits'''\n",
    "    n = 0\n",
    "    while n < N:\n",
    "        for n in range(0, N):\n",
    "            limits.append(limits[n] + intervals)\n",
    "            n += n                  \n",
    "    return limits[:-2]  \n",
    "classes(N)\n",
    "\n",
    "def cl_equal_intevals(X):\n",
    "    '''The function assigns lables depending on which interval a data point falls into'''    \n",
    "    for x in X:\n",
    "        if x < limits[1]: return '1'\n",
    "        elif (x >= limits[1]) * (x < limits[2]): return '2'\n",
    "        elif (x >= limits[2]) * (x < limits[3]): return '3'\n",
    "        elif (x >= limits[3]) * (x < limits[4]): return '4'        \n",
    "        else: return '5'\n",
    "        \n",
    "df['cluster'] = df[['Values']].apply(cl_equal_intevals, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_tbl = pd.DataFrame(df.loc[:, ['Values', 'cluster']].groupby(str('cluster')).count().iloc[:,0]).reset_index()\n",
    "#Building a frequency plot\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(freq_tbl['cluster'], freq_tbl['Values'], alpha = 0.3)\n",
    "_ = plt.title('Frequency plot')\n",
    "_ = plt.xlabel('Classes')\n",
    "_ = plt.ylabel('Density')\n",
    "_ = ax.set_xticks([0, 1,2,3, 4, 5]) \n",
    "_ = ax.set_xticklabels(['(- 22)','[22-28)','[28-34)', '[34-40)', '[40-46)', '[46 -)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating cumulative frequency\n",
    "freq_tbl['Cumulative_frequency'] = freq_tbl['Values'].cumsum()\n",
    "freq_tbl['Relative_cumulative_frequency'] = freq_tbl['Cumulative_frequency']/max(freq_tbl['Cumulative_frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "plt.plot(freq_tbl['cluster'], freq_tbl['Cumulative_frequency'], color='none')\n",
    "ax1.set_ylabel(\"Number of x\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.yaxis.set_label_position(\"right\")\n",
    "plt.plot(freq_tbl['cluster'], freq_tbl['Relative_cumulative_frequency'])\n",
    "ax2.set_xlabel(\"Value\")\n",
    "ax2.set_ylabel(\"Percent of x\")\n",
    "ax2.set_xticks([0, 1,2,3, 4, 5]) \n",
    "ax2.set_xticklabels(['(- 22)','[22-28)','[28-34)', '[34-40)', '[40-46)', '[46 -)'])\n",
    "\n",
    "plt.title('Cumulative frequency plot')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the average\n",
    "df['Values'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the weighted average\n",
    "df_freq = df.groupby('Values').count()\n",
    "df_freq = df_freq.reset_index()\n",
    "def wavg(group, avg_name, weight_name):\n",
    "    \"\"\" Calculating the weighted average in a df \"\"\"\n",
    "    d = group[avg_name]\n",
    "    w = group[weight_name]\n",
    "    return (d * w).sum() / w.sum()\n",
    "wavg(df_freq, \"Values\", \"cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the geometric average\n",
    "scipy.stats.gmean(df[\"Values\"],axis = 0)\n",
    "def geom_mean(avg_name):\n",
    "    return ((avg_name.iloc[-1] / avg_name.iloc[0]) ** (1/len(avg_name))) - 1\n",
    "geom_mean(df['Values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a boxplot\n",
    "plt.boxplot(df['Values'])\n",
    "plt.title('Boxplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating skeweness using PEARSON’S COEFFICIENT OF SKEWNESS \n",
    "arr = [557,\t542,\t419,\t416,\t396,\t351,\t313,\t305,\t285,\t281,\t269,\t264,\t252,\t249,\t248,\t248,\t240,\t239,\t235,\t235,\t233,\t224,\t219,\t217,\t211,\t207,\t205,\t199,\t198,\t179,\t178,\t175,\t174,\t172,\t169,\t166,\t165,\t162,\t157,\t149,\t145,\t145,\t136,\t132,\t128,\t124,\t120,\t107,\t107,\t103,\t100,\t95,\t94,\t94,\t92,\t91,\t80,\t66,\t59,\t44]\n",
    "df = pd.DataFrame(arr)\n",
    "coef_of_skeweness = (3 * (df.mean() - df.median()))/ df.std()\n",
    "#coef_of_skeweness > 0, thus, it indicates positive skeweness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating confidence interval using z distribution\n",
    "bottom = np.mean(arr) - 1.96*np.std(arr)/(np.sqrt(len(arr)))\n",
    "upper = np.mean(arr) + 1.96*np.std(arr)/(np.sqrt(len(arr)))\n",
    "print '30 days 95% confidence inverval:', (bottom,upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [7077,  5744,  6753,  7381,  7625,  6636,  7164,  7348,  8060,  5848,  9275,  7052]\n",
    "#Calculating t statistic\n",
    "t = (np.mean(arr)-6658)/(np.sqrt((((arr-np.mean(arr))**2)/(len(arr)-1)).sum())/np.sqrt(12)); t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [29.7 , 29.4  ,31.7  ,29.0  ,29.1  ,30.5 , 29.1 , 29.]\n",
    "#Calculating t statistic\n",
    "def t_stat(arr, pop_mean):\n",
    "    \"\"\"The function calculates t statistic\"\"\"\n",
    "    return (np.mean(arr)-pop_mean)/(np.sqrt((((arr-np.mean(arr))**2)/(len(arr)-1)).sum())/np.sqrt(len(arr)))\n",
    "t_stat(arr, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = [10, 12, 15, 19]\n",
    "arr2 = [8, 9, 12, 15]\n",
    "def t_statistic_two_sample(arr1, arr2):\n",
    "    '''The function calculates t statistic for two-sample test of hypothesis for dependent samples'''\n",
    "    substr = list(np.array(arr1) - np.array(arr2))\n",
    "    avg = np.mean(substr)\n",
    "    dif_from_mean = (substr - avg)**2\n",
    "    st_dev = (sum(dif_from_mean)/ (len(arr1) - 1))**0.5\n",
    "    t_statistic = avg / (st_dev / (len(arr1))**0.5)\n",
    "    return t_statistic\n",
    "t_statistic_two_sample(arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = [ 6.6, 6.5, 9.0, 10.3, 11.2, 8.1, 6.3, 11.6]\n",
    "after = [ 6.8 ,2.4, 7.4, 8.5, 8.1, 6.1, 3.4,  2]\n",
    "t_statistic_two_sample(before, after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_statistic_two_sample(x_bar_1, x_bar_2, std_1, std_2, n_1, n_2):\n",
    "    '''The function calculates z statistic for two-sample test of hypothesis with population mean known for independent samples'''\n",
    "    z = (x_bar_1 - x_bar_2) / ((std_1**2 / n_1) + (std_2**2 / n_2))**0.5\n",
    "    return z\n",
    "z_statistic_two_sample(57000, 61000, 9200, 7100, 40, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_statistic_two_sample_unequal(x_bar_1, x_bar_2, std_1, std_2, n_1, n_2):\n",
    "    '''The function calculates t statistic when population standard deviation is unknown under the assumption that the populations are not equal'''\n",
    "    df = ((std_1**2 / n_1) + (std_2**2 / n_2))**2 / (((std_1**2/n_1)**2)/(n_1 - 1) + ((std_2**2/n_2)**2)/(n_2 - 1))\n",
    "    t = (x_bar_1 - x_bar_2) / ((std_1**2 / n_1) + (std_2**2 / n_2))**0.5\n",
    "    return t, df\n",
    "t_statistic_two_sample_unequal(83.55, 78.80, 10.50, 14.25, 10, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_statistic_two_sample_equal(x_bar_1, x_bar_2, std_1, std_2, n_1, n_2):\n",
    "    '''The function calculates t statistic when population standard deviation is unknow under the assumption that population have equal deviations'''\n",
    "    sp = ((n_1 - 1)*std_1**2 + (n_2 - 1)*std_2**2) / (n_1 + n_2 - 2)\n",
    "    t = (x_bar_1 - x_bar_2) / (sp * ((1/float(n_1)) + (1/float(n_2))))**0.5\n",
    "    return sp,t\n",
    "t_statistic_two_sample_equal(83.55, 78.80, 10.50, 14.25, 10, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1 = [138, 121,  88 ,115, 141, 125,96  ]\n",
    "arr_2 = [128 ,134, 152 ,135, 114 ,106 ,112, 120]\n",
    "def pre_processing(arr_1, arr_2):\n",
    "    global x_bar_1, x_bar_2, std_1, std_2    \n",
    "    x_bar_1 = np.mean(arr_1)\n",
    "    x_bar_2 = np.mean(arr_2)\n",
    "    std_1 = np.std(arr_1, ddof=1)\n",
    "    std_2 = np.std(arr_2, ddof=1)\n",
    "    return x_bar_1, x_bar_2, std_1, std_2\n",
    "pre_processing(arr_1, arr_2)\n",
    "t_statistic_two_sample_equal(x_bar_1, x_bar_2, std_1, std_2, 7, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_statistic_two_sample_equal(150000, 180000,40000,30000,15,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Anova\n",
    "arr_1 = [98, 78, 54, 57, 68, 64, 70]\n",
    "arr_2 = [75, 81, 81, 30, 82, 46, 58, 101]\n",
    "stats.f_oneway(arr_1, arr_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way to do Anova\n",
    "#One-way Anova\n",
    "arr_1 = [18, 16, 21, 23, 25]\n",
    "arr_2 = [17, 23, 21, 22, 24]\n",
    "arr_3 = [21, 23, 26, 29, 28]\n",
    "arr_4 = [22, 22, 22, 25, 28]\n",
    "lst = arr_1 + arr_2 + arr_3 + arr_4\n",
    "def variation(data): \n",
    "    \"\"\"The function calculates variations\"\"\"\n",
    "    global avg\n",
    "    avg = sum(data) / float(len(data))  \n",
    "    vari = 0\n",
    "    for d in data:\n",
    "        vari += (d - avg)**2\n",
    "    return vari\n",
    "SSE = variation(arr_1) + variation(arr_2) + variation(arr_3) + variation(arr_4)\n",
    "SS = variation(lst)\n",
    "SST = SS - SSE\n",
    "def f_statistic(SST, SSE, n_arr, lst):\n",
    "    \"\"\"The function calculation f statistic\"\"\"\n",
    "    MST = SST / (n_arr - 1)\n",
    "    MSE = SSE / (len(lst) - n_arr)\n",
    "    return MST / MSE\n",
    "f_statistic(SST, SSE, 4, lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alternative way to calculate one-way Anova\n",
    "arr_1 = [18, 16, 21, 23, 25]\n",
    "arr_2 = [17, 23, 21, 22, 24]\n",
    "arr_3 = [21, 23, 26, 29, 28]\n",
    "arr_4 = [22, 22, 22, 25, 28]\n",
    "df = pd.DataFrame(np.vstack((arr_1, arr_2, arr_3, arr_4)))\n",
    "df = df.T\n",
    "def SS(data): \n",
    "    \"\"\"The function calculates SS\"\"\"\n",
    "    avg = (float(data.values.sum()) / float(data.size))\n",
    "    vari = ((data - avg)**2).values.sum()\n",
    "    return vari\n",
    "def SSE(data): \n",
    "    \"\"\"The function calculates SSE\"\"\"\n",
    "    vari = ((data - np.mean(data))**2).values.sum()\n",
    "    return vari\n",
    "def SST(SS, SSE):\n",
    "    \"\"\"The function calculates SST\"\"\"\n",
    "    dif = SS - SSE\n",
    "    return dif\n",
    "def f_statistic(SST, SSE, n_treat, data):\n",
    "    \"\"\"The function calculation f statistic\"\"\"\n",
    "    MST = SST / (n_treat - 1)\n",
    "    MSE = SSE / (float(data.size) - n_treat)\n",
    "    return (MST/MSE)\n",
    "f_statistic(SST(SS(df), SSE(df)), SSE(df), 4, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two-way Anova\n",
    "#Alternative way to calculate one-way Anova\n",
    "arr_1 = [18, 16, 21, 23, 25]\n",
    "arr_2 = [17, 23, 21, 22, 24]\n",
    "arr_3 = [21, 23, 26, 29, 28]\n",
    "arr_4 = [22, 22, 22, 25, 28]\n",
    "df = pd.DataFrame(np.vstack((arr_1, arr_2, arr_3, arr_4)))\n",
    "df = df.T\n",
    "def SS(data): \n",
    "    \"\"\"The function calculates SS\"\"\"\n",
    "    global global_avg\n",
    "    global_avg = (float(data.values.sum()) / float(data.size))\n",
    "    vari = ((data - global_avg)**2).values.sum()\n",
    "    return vari\n",
    "def SSB(data, n_treat):\n",
    "    SS(data)\n",
    "    \"\"\"The function calculates SSB\"\"\"\n",
    "    local_avg =  np.mean(data, axis = 1)\n",
    "    vari = (n_treat * (local_avg - global_avg)**2).values.sum()\n",
    "    return vari\n",
    "def SSE(data): \n",
    "    \"\"\"The function calculates SSE\"\"\"\n",
    "    vari = ((data - np.mean(data))**2).values.sum()\n",
    "    return vari\n",
    "def SST(SS, SSE):\n",
    "    \"\"\"The function calculates SST\"\"\"\n",
    "    dif = SS - SSE\n",
    "    return dif\n",
    "def SSE_2(SS, SST, SSB): \n",
    "    \"\"\"The function calculates SSE\"\"\"\n",
    "    dif = SS - SST - SSB\n",
    "    return dif\n",
    "def f_statistic(SST, SSE_2, n_treat, data):\n",
    "    \"\"\"The function calculation f statistic\"\"\"\n",
    "    MST = SST / (n_treat - 1)\n",
    "    MSE = SSE_2 / ((n_treat - 1)*(len(data.index) - 1))\n",
    "    return (MST / MSE)\n",
    "f_statistic(SST(SS(df), SSE(df)), SSE_2(SS(df), SST(SS(df), SSE(df)), SSB(df, 4)), 4, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1 = [31, 33, 28, 30, 28]\n",
    "arr_2 = [25, 26, 24, 29, 26]\n",
    "arr_3 = [35, 33, 30, 28, 27]\n",
    "df = pd.DataFrame(np.vstack((arr_1, arr_2, arr_3)))\n",
    "df = df.T\n",
    "def SS(data): \n",
    "    \"\"\"The function calculates SS\"\"\"\n",
    "    global global_avg\n",
    "    global_avg = (float(data.values.sum()) / float(data.size))\n",
    "    vari = ((data - global_avg)**2).values.sum()\n",
    "    return vari\n",
    "def SSB(data, n_treat):\n",
    "    SS(data)\n",
    "    \"\"\"The function calculates SSB\"\"\"\n",
    "    local_avg =  np.mean(data, axis = 1)\n",
    "    vari = (n_treat * (local_avg - global_avg)**2).values.sum()\n",
    "    return vari\n",
    "def SSE(data): \n",
    "    \"\"\"The function calculates SSE\"\"\"\n",
    "    vari = ((data - np.mean(data))**2).values.sum()\n",
    "    return vari\n",
    "def SST(SS, SSE):\n",
    "    \"\"\"The function calculates SST\"\"\"\n",
    "    dif = SS - SSE\n",
    "    return dif\n",
    "def SSE_2(SS, SST, SSB): \n",
    "    \"\"\"The function calculates SSE\"\"\"\n",
    "    dif = SS - SST - SSB\n",
    "    return dif\n",
    "def f_statistic(SST, SSE_2, SSB, n_treat, data):\n",
    "    \"\"\"The function calculation f statistic\"\"\"\n",
    "    MST = SST / (n_treat - 1)\n",
    "    MSE = SSE_2 / ((n_treat - 1)*(len(data.index) - 1))\n",
    "    treatment_f = (MST / MSE)\n",
    "    MSB = SSB / (len(data.index)-1)\n",
    "    blocks_f = MSB / MSE\n",
    "    return blocks_f, treatment_f\n",
    "f_statistic(SST(SS(df), SSE(df)), SSE_2(SS(df), SST(SS(df), SSE(df)), SSB(df, 3)), SSB(df, 3), 3, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise\n",
    "arr_1 = [31, 33, 28, 30, 28]\n",
    "arr_2 = [25, 26, 24, 29, 26]\n",
    "lst = arr_1 + arr_2\n",
    "def variation(data): \n",
    "    \"\"\"The function calculates variations\"\"\"\n",
    "    global avg\n",
    "    avg = sum(data) / float(len(data))  \n",
    "    vari = 0\n",
    "    for d in data:\n",
    "        vari += (d - avg)**2\n",
    "    return vari\n",
    "SSE = variation(arr_1) + variation(arr_2)\n",
    "SS = variation(lst)\n",
    "SST = SS - SSE\n",
    "def f_statistic(SST, SSE, n_arr, lst):\n",
    "    \"\"\"The function calculation f statistic\"\"\"\n",
    "    MST = SST / (n_arr - 1)\n",
    "    MSE = SSE / (len(lst) - n_arr)\n",
    "    return MST / MSE\n",
    "f_statistic(SST, SSE, 2, lst)\n",
    "#stats.f_oneway(arr_1, arr_2, arr_3, arr_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation and regression analysis\n",
    "arr_1 = [4,2,5,6,3 ]\n",
    "arr_2 = [15,8,21,24,17]\n",
    "pearson_coef, p_value = stats.pearsonr(arr_1, arr_2) #define the columns to perform calculations on\n",
    "print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check if there are 0 correlation in the population\n",
    "def t_test_pearson(r, n):\n",
    "    \"\"\"The function calculates t statistic for pearson coefficient\"\"\"\n",
    "    t = (r * ((n - 2)**0.5)) / (1 - r**2)**0.5\n",
    "    return t\n",
    "t_test_pearson(0.78, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Coming up with regression equation\n",
    "x = [89.2, 18.6, 18.2, 71.7, 58.6, 46.8, 17.5, 11.9, 19.6, 51.2, 28.6, 69.2]\n",
    "y = [4.9, 4.4, 1.3, 8, 6.6, 4.1, 2.6, 1.7, 3.5, 8.2, 6, 12.8]\n",
    "def regression_equation(arr_1, arr_2):\n",
    "    \"\"\"The function prepares the regression equation\"\"\"\n",
    "    x_bar = np.mean(arr_1)\n",
    "    y_bar = np.mean(arr_2)\n",
    "    std_x = np.std(arr_1)\n",
    "    std_y = np.std(arr_2)    \n",
    "    pearson_coef, p_value = stats.pearsonr(arr_1, arr_2)\n",
    "    b = pearson_coef * (float(std_y) / float(std_x))\n",
    "    a = y_bar - b * x_bar\n",
    "    return a, b, pearson_coef\n",
    "regression_equation(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_1 = [-8, -16, 12, 2, 18]\n",
    "arr_2 = [58, 247, 15, 3, 341]\n",
    "plt.scatter(arr_2,arr_1)\n",
    "_= plt.title('Exploring relationship btw x and y')\n",
    "_ = plt.ylabel('Y')\n",
    "_= plt.xlabel('X')\n",
    "plt.show()\n",
    "pearson_coef, p_value = stats.pearsonr( arr_2,arr_1) #define the columns to perform calculations on\n",
    "print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transforming x to get linear relationship\n",
    "arr_1_2 = []\n",
    "arr_1 = [-8, -16, 12, 2, 18]\n",
    "\n",
    "for i in arr_1:\n",
    "    l = i **2\n",
    "    arr_1_2.append(l)\n",
    "arr_2 = [58, 247, 15, 3, 341]\n",
    "plt.scatter(arr_1_2,arr_1)\n",
    "_= plt.title('Exploring relationship btw x and y')\n",
    "_ = plt.ylabel('Y')\n",
    "_= plt.xlabel('X')\n",
    "plt.show()\n",
    "pearson_coef, p_value = stats.pearsonr( arr_2,arr_1) #define the columns to perform calculations on\n",
    "print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_test_pearson(r, n):\n",
    "    \"\"\"The function calculates t statistic for pearson coefficient\"\"\"\n",
    "    t = (r * ((n - 2)**0.5)) / (1 - r**2)**0.5\n",
    "    return t\n",
    "t_test_pearson(0.47, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [6, 7.8, 7.3, 10.3, 10.1, 10.8, 11.5, 15.4, 13.5, 15.5, 17.4, 16.9, 11.6, 17.5]\n",
    "y = [50.2, 50.4, 44, 49.9, 39.5, 43.1, 44, 40.1, 36, 31.7, 28.6, 26.9, 19.1, 17.6]\n",
    "\n",
    "fig = plt.figure(figsize=(2.2,2.2), dpi=100)\n",
    "ax = plt.subplot(111)\n",
    "plt.xlim(np.min(x), np.max(x))\n",
    "plt.ylim(np.min(y), np.max(y))\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "line = slope*np.array(x)+intercept\n",
    "plt.plot(x, line, 'r', label='y={:.2f}x+{:.2f}'.format(slope,intercept))\n",
    "plt.scatter(x,y, color=\"k\", s=3.5)\n",
    "_= plt.title('Exploring relationship btw x and y')\n",
    "_ = plt.ylabel('Y')\n",
    "_= plt.xlabel('X')\n",
    "plt.show()\n",
    "pearson_coef, p_value = stats.pearsonr( x,y) #define the columns to perform calculations on\n",
    "print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results \n",
    "\n",
    "def t_test_pearson(r, n):\n",
    "    \"\"\"The function calculates t statistic for pearson coefficient\"\"\"\n",
    "    t = (r * ((n - 2)**0.5)) / (1 - r**2)**0.5\n",
    "    return t\n",
    "t_test_pearson(-0.7468153584290134, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [12, 2, 6, 9, 7, 2, 8, 4, 10, 5]\n",
    "y = [4, 10, 8, 5, 5, 8, 3, 8, 2, 5]\n",
    "\n",
    "fig = plt.figure(figsize=(2.2,2.2), dpi=100)\n",
    "ax = plt.subplot(111)\n",
    "plt.xlim(np.min(x), np.max(x))\n",
    "plt.ylim(np.min(y), np.max(y))\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "line = slope*np.array(x)+intercept\n",
    "plt.plot(x, line, 'r', label='y={:.2f}x+{:.2f}'.format(slope,intercept))\n",
    "plt.scatter(x,y, color=\"k\", s=3.5)\n",
    "_= plt.title('Exploring relationship btw x and y')\n",
    "_ = plt.ylabel('Y')\n",
    "_= plt.xlabel('X')\n",
    "plt.show()\n",
    "pearson_coef, p_value = stats.pearsonr( x,y) #define the columns to perform calculations on\n",
    "print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results \n",
    "\n",
    "def t_test_pearson(r, n):\n",
    "    \"\"\"The function calculates t statistic for pearson coefficient\"\"\"\n",
    "    t = (r * ((n - 2)**0.5)) / (1 - r**2)**0.5\n",
    "    return t\n",
    "t_test_pearson(-0.8269396448751986, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [2.833, 1.233, 2.144, 3.849, 8.124, 1.448, 1.51, 1.297, 1.257, 0.930]\n",
    "y = [31.5, 30.5, 30.9, 31.6, 34.2, 34.2, 30.7, 31.7, 32.5, 32.6]\n",
    "\n",
    "fig = plt.figure(figsize=(2.2,2.2), dpi=100)\n",
    "ax = plt.subplot(111)\n",
    "plt.xlim(np.min(x), np.max(x))\n",
    "plt.ylim(np.min(y), np.max(y))\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "line = slope*np.array(x)+intercept\n",
    "plt.plot(x, line, 'r', label='y={:.2f}x+{:.2f}'.format(slope,intercept))\n",
    "plt.scatter(x,y, color=\"k\", s=3.5)\n",
    "_= plt.title('Exploring relationship btw x and y')\n",
    "_ = plt.ylabel('Y')\n",
    "_= plt.xlabel('X')\n",
    "plt.show()\n",
    "pearson_coef, p_value = stats.pearsonr( x,y) #define the columns to perform calculations on\n",
    "print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results \n",
    "\n",
    "\n",
    "def t_test_pearson(r, n):\n",
    "    \"\"\"The function calculates t statistic for pearson coefficient\"\"\"\n",
    "    t = (r * ((n - 2)**0.5)) / (1 - r**2)**0.5\n",
    "    return t\n",
    "t_test_pearson(0.44972718100719067, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [9, 9, 3, 10, 5, 10, 7, 11, 6, 6, 4, 7, 7, 7, 6]\n",
    "y = [5.1, 8, 9.7, 7.8, 7.7, 5.5, 8.3, 5.5, 10.3, 8, 8.8, 9.4, 8.6, 8.1, 7.8]\n",
    "def regression_equation(arr_1, arr_2):\n",
    "    \"\"\"The function prepares the regression equation\"\"\"\n",
    "    x_bar = np.mean(arr_1)\n",
    "    y_bar = np.mean(arr_2)\n",
    "    std_x = np.std(arr_1)\n",
    "    std_y = np.std(arr_2)    \n",
    "    pearson_coef, p_value = stats.pearsonr(arr_1, arr_2)\n",
    "    b = pearson_coef * (float(std_y) / float(std_x))\n",
    "    a = y_bar - b * x_bar\n",
    "    return a, b, pearson_coef\n",
    "regression_equation(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indices\n",
    "p_c_list = []\n",
    "p_t = [69220, 54818, 55177, 65694, 83040, 88378, 97420, 98608]\n",
    "for p in p_t:\n",
    "    p_comp = (float(p)/ float(p_t[0]) ) * 100\n",
    "    p_c_list.append(p_comp)\n",
    "print p_c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_c_list = []\n",
    "p_t = [486.6, 506.8, 522.2 ,574.6, 580.7, 568.5, 581.9, 496.1, 456.6, 433.3]\n",
    "for p in p_t:\n",
    "    p_comp = (float(p)/ float((p_t[0]+p_t[1]+p_t[2])/3 )) * 100\n",
    "    p_c_list.append(p_comp)\n",
    "print p_c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_0 = [2.49, 3.29, 1.59, 1.79]\n",
    "q_0 = [6, 4, 2, 3]\n",
    "p_t = [ 3.35, 4.49, 4.19, 2.49]\n",
    "q_t = [ 6, 5, 3, 4]\n",
    "p_c_list = []\n",
    "for p in p_t:\n",
    "    p_comp = (float(p)/ float((p_0[0] + p_0[1] + p_0[2] + p_0[3])/4) ) * 100\n",
    "    p_c_list.append(p_comp)\n",
    "print p_c_list\n",
    "p_simple_agg = float((p_t[0] + p_t[1] + p_t[2] + p_t[3])) / float((p_0[0] + p_0[1] + p_0[2] + p_0[3]))\n",
    "print p_simple_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Laspeyres price index\n",
    "df_base = pd.DataFrame(np.vstack((p_0, q_0)))\n",
    "df_base = df_base.T\n",
    "df_base.columns = ['price_2000', 'qunatity_2010']\n",
    "p0_q0 = df_base.iloc[:,0].multiply(df_base.iloc[:,1]).sum()\n",
    "\n",
    "df_t = pd.DataFrame(np.vstack((p_t, q_t)))\n",
    "df_t = df_t.T\n",
    "df_t.columns = ['price_2017', 'qunatity_2017']\n",
    "pt_q0 = df_t.iloc[:,0].multiply(df_base.iloc[:,1]).sum()\n",
    "lasp_index = (pt_q0 / p0_q0) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Paashce price index\n",
    "df_base = pd.DataFrame(np.vstack((p_0, q_0)))\n",
    "df_base = df_base.T\n",
    "df_t = pd.DataFrame(np.vstack((p_t, q_t)))\n",
    "df_t = df_t.T\n",
    "df_t.columns = ['price_2017', 'qunatity_2017']\n",
    "pt_q0 = df_t.iloc[:,0].multiply(df_t.iloc[:,1]).sum()\n",
    "\n",
    "df_base.columns = ['price_2000', 'qunatity_2010']\n",
    "p0_q0 = df_base.iloc[:,0].multiply(df_t.iloc[:,1]).sum()\n",
    "paasheche_index = (pt_q0 / p0_q0)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Fisher's Ideal index\n",
    "fisher_index = ((lasp_index * paasheche_index)**0.5)\n",
    "print(lasp_index, paasheche_index, fisher_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Value index\n",
    "p_0 = [1.81, 3.56,2.32,2.72]\n",
    "q_0 = [116,2, 8967, 227]\n",
    "p_t = [ 2.09, 5.99, 3.65, 5.53]\n",
    "q_t = [ 90, 2, 13601, 214]\n",
    "df = pd.DataFrame(np.vstack((p_0, q_0,p_t, q_t)))\n",
    "df = df.T\n",
    "df.columns = ['price_02', 'qnty_02', 'price_15', 'qnty_15']\n",
    "v = ((df.iloc[:,2].multiply(df.iloc[:,3]).sum())  / (df.iloc[:,0].multiply(df.iloc[:,1]).sum()))*100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_domestic = [17316, 19825, 22455, 25274, 2770, 28377, 29775, 32444, 32309, 30889, 29437, 28907, 29830, 31910, 34782, 35687]\n",
    "p_international = [11856, 12492, 13843, 16588, 19578, 22137, 23549, 28651, 31438, 31008, 32124, 36107, 37394, 39402, 39548, 34387]\n",
    "p_employees = [100.9, 101.8, 108.3, 110.6, 109.9, 115.6, 122.2, 119.2, 118.7, 115.5, 114, 117.9, 127.6, 128.1, 126.5, 127.1]\n",
    "p_dom = []\n",
    "for p in p_domestic:\n",
    "    p_comp = (float(p)/ float(p_domestic[0])) * 100\n",
    "    p_dom.append(p_comp)\n",
    "print p_dom\n",
    "plt.plot(p_dom)\n",
    "_= plt.title('Index of domestic sales (2000=100)')\n",
    "_ = plt.xticks(np.arange(16), ('2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015'))\n",
    "_ = plt.xticks(rotation=70)\n",
    "_ = plt.ylabel('Index')\n",
    "_ = plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_int = []\n",
    "for p in p_international:\n",
    "    p_comp_in = (float(p)/ float(p_international[0])) * 100\n",
    "    p_int.append(p_comp_in)\n",
    "print p_int\n",
    "plt.plot(p_int)\n",
    "_= plt.title('Index of domestic sales (2000=100)')\n",
    "_ = plt.xticks(np.arange(16), ('2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015'))\n",
    "_ = plt.xticks(rotation=70)\n",
    "_ = plt.ylabel('Index')\n",
    "_ = plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_empl = []\n",
    "for p in p_employees:\n",
    "    p_comp_emp = (float(p)/ float(p_employees[0])) * 100\n",
    "    p_empl.append(p_comp_emp)\n",
    "print p_empl\n",
    "plt.plot(p_empl)\n",
    "_= plt.title('Index of domestic sales (2000=100)')\n",
    "_ = plt.xticks(np.arange(16), ('2000', '2001', '2002', '2003', '2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015'))\n",
    "_ = plt.xticks(rotation=70)\n",
    "_ = plt.ylabel('Index')\n",
    "_ = plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_revenue = [134, 152, 157, 168, 177, 183, 150, 147, 147, 146, 149, 151]\n",
    "p_employees= [325, 307, 316, 319, 327, 323, 304, 287, 301, 307, 305, 333]\n",
    "p_revenue_list = []\n",
    "for p in p_revenue:\n",
    "    p_com_rev = (float(p)/ float(p_revenue[0])) * 100\n",
    "    p_revenue_list.append(p_com_rev)\n",
    "print p_revenue_list\n",
    "plt.plot(p_revenue_list)\n",
    "_= plt.title('Index of GE Revenue (2004=100)')\n",
    "_ = plt.xticks(np.arange(12), ('2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015'))\n",
    "_ = plt.xticks(rotation=70)\n",
    "_ = plt.ylabel('Index')\n",
    "_ = plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_empl_list = []\n",
    "for p in p_employees:\n",
    "    p_com_empl = (float(p)/ float(p_employees[0])) * 100\n",
    "    p_empl_list.append(p_com_empl)\n",
    "print p_empl_list\n",
    "plt.plot(p_empl_list)\n",
    "_= plt.title('Index of # of GE employees (2004=100)')\n",
    "_ = plt.xticks(np.arange(12), ('2004', '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013', '2014', '2015'))\n",
    "_ = plt.xticks(rotation=70)\n",
    "_ = plt.ylabel('Index')\n",
    "_ = plt.xlabel('Year')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_0 = [0.81, 0.84, 1.44, 2.91]\n",
    "q_0 = [18, 5, 70, 27]\n",
    "p_t = [2, 1.88, 2.89, 3.99]\n",
    "q_t = [27, 9, 65, 33]\n",
    "#Calculating simple index\n",
    "p_simple = [float((ai)/bi)*100 for ai,bi in zip(p_t,p_0)]\n",
    "\n",
    "#Calculating Laspeyres price index\n",
    "df_base = pd.DataFrame(np.vstack((p_0, q_0)))\n",
    "df_base = df_base.T\n",
    "df_base.columns = ['price_2000', 'qunatity_2000']\n",
    "p0_q0 = df_base.iloc[:,0].multiply(df_base.iloc[:,1]).sum()\n",
    "df_t = pd.DataFrame(np.vstack((p_t, q_t)))\n",
    "df_t = df_t.T\n",
    "df_t.columns = ['price_2016', 'qunatity_2016']\n",
    "pt_q0 = df_t.iloc[:,0].multiply(df_base.iloc[:,1]).sum()\n",
    "lasp_index = (pt_q0 / p0_q0) * 100\n",
    "\n",
    "#Calculating Paashce price index\n",
    "df_base = pd.DataFrame(np.vstack((p_0, q_0)))\n",
    "df_base = df_base.T\n",
    "df_t = pd.DataFrame(np.vstack((p_t, q_t)))\n",
    "df_t = df_t.T\n",
    "df_t.columns = ['price_2016', 'qunatity_2016']\n",
    "pt_q0 = df_t.iloc[:,0].multiply(df_t.iloc[:,1]).sum()\n",
    "df_base.columns = ['price_2000', 'qunatity_2000']\n",
    "p0_q0 = df_base.iloc[:,0].multiply(df_t.iloc[:,1]).sum()\n",
    "paasheche_index = (pt_q0 / p0_q0)*100\n",
    "\n",
    "#Calculating Fisher's Ideal index\n",
    "fisher_index = ((lasp_index * paasheche_index)**0.5)\n",
    "print(p_simple, lasp_index, paasheche_index, fisher_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_0 = [0.50, 1.20, 0.85]\n",
    "q_0 = [320, 110, 230]\n",
    "p_t = [0.60, 0.90, 1]\n",
    "q_t = [340, 130, 250]\n",
    "#Calculating simple index\n",
    "p_simple = [float((ai)/bi)*100 for ai,bi in zip(p_t,p_0)]\n",
    "\n",
    "#Calculating Laspeyres price index\n",
    "df_base = pd.DataFrame(np.vstack((p_0, q_0)))\n",
    "df_base = df_base.T\n",
    "df_base.columns = ['price_2000', 'qunatity_2000']\n",
    "p0_q0 = df_base.iloc[:,0].multiply(df_base.iloc[:,1]).sum()\n",
    "df_t = pd.DataFrame(np.vstack((p_t, q_t)))\n",
    "df_t = df_t.T\n",
    "df_t.columns = ['price_2016', 'qunatity_2016']\n",
    "pt_q0 = df_t.iloc[:,0].multiply(df_base.iloc[:,1]).sum()\n",
    "lasp_index = (pt_q0 / p0_q0) * 100\n",
    "\n",
    "#Calculating Paashce price index\n",
    "df_base = pd.DataFrame(np.vstack((p_0, q_0)))\n",
    "df_base = df_base.T\n",
    "df_t = pd.DataFrame(np.vstack((p_t, q_t)))\n",
    "df_t = df_t.T\n",
    "df_t.columns = ['price_2016', 'qunatity_2016']\n",
    "pt_q0 = df_t.iloc[:,0].multiply(df_t.iloc[:,1]).sum()\n",
    "df_base.columns = ['price_2000', 'qunatity_2000']\n",
    "p0_q0 = df_base.iloc[:,0].multiply(df_t.iloc[:,1]).sum()\n",
    "paasheche_index = (pt_q0 / p0_q0)*100\n",
    "\n",
    "#Calculating Fisher's Ideal index\n",
    "fisher_index = ((lasp_index * paasheche_index)**0.5)\n",
    "print(p_simple, lasp_index, paasheche_index, fisher_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Midterm\n",
    "arr_1 =  [2.56,2.77,2.7,3,2.98,3.47,3.26,3.2,3.19,2.65,3,3.39,2.58]\n",
    "arr_2 = [3.04,1.71,3.3,2.88,2.11,2.6,2.92,3.6,2.28,2.82,3.03,3.13,2.86,3.49,3.11,2.13,3.27]\n",
    "def pre_processing(arr_1, arr_2):\n",
    "    global x_bar_1, x_bar_2, std_1, std_2    \n",
    "    x_bar_1 = np.mean(arr_1)\n",
    "    x_bar_2 = np.mean(arr_2)\n",
    "    std_1 = np.std(arr_1, ddof=1)\n",
    "    std_2 = np.std(arr_2, ddof=1)\n",
    "    return x_bar_1, x_bar_2, std_1, std_2\n",
    "pre_processing(arr_1, arr_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_statistic_two_sample_equal(x_bar_1, x_bar_2, std_1, std_2, n_1, n_2):\n",
    "    '''The function calculates t statistic when population standard deviation is unknow under the assumption that population have equal deviations'''\n",
    "    sp = ((n_1 - 1)*std_1**2 + (n_2 - 1)*std_2**2) / (n_1 + n_2 - 2)\n",
    "    t = (x_bar_1 - x_bar_2) / (sp * ((1/float(n_1)) + (1/float(n_2))))**0.5\n",
    "    return sp,t\n",
    "t_statistic_two_sample_equal(x_bar_1, x_bar_2, std_1, std_2, 13, 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Midterm\n",
    "arr_1 =  [2,4,9,3,2]\n",
    "arr_2 = [3,7,5,8,4,3]\n",
    "def pre_processing(arr_1, arr_2):\n",
    "    global x_bar_1, x_bar_2, std_1, std_2    \n",
    "    x_bar_1 = np.mean(arr_1)\n",
    "    x_bar_2 = np.mean(arr_2)\n",
    "    std_1 = np.std(arr_1, ddof=1)\n",
    "    std_2 = np.std(arr_2, ddof=1)\n",
    "    return x_bar_1, x_bar_2, std_1, std_2\n",
    "pre_processing(arr_1, arr_2)\n",
    "def t_statistic_two_sample_equal(x_bar_1, x_bar_2, std_1, std_2, n_1, n_2):\n",
    "    '''The function calculates t statistic when population standard deviation is unknow under the assumption that population have equal deviations'''\n",
    "    sp = ((n_1 - 1)*std_1**2 + (n_2 - 1)*std_2**2) / (n_1 + n_2 - 2)\n",
    "    t = (x_bar_1 - x_bar_2) / (sp * ((1/float(n_1)) + (1/float(n_2))))**0.5\n",
    "    return sp,t\n",
    "t_statistic_two_sample_equal(x_bar_1, x_bar_2, std_1, std_2, 5, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,1.5,2.75,3,3.25,3.5,3.75,3.75,4,4,4.25,4.5,4.5,4.5,4.75,4.75,4.75,5,5,5,5.25,5.25,5.5,5.5,6,6.25]\n",
    "y = [1,1.5,1.5,3,3.25,2.5,4,4.5,4,4.5,5.25,2.75,4.25,4.5,3.25,4.5,4.75,4.75,5,5.25,4.5,4.75,4,5.75,4.5,5]\n",
    "\n",
    "fig = plt.figure(figsize=(2.2,2.2), dpi=400)\n",
    "ax = plt.subplot(111)\n",
    "plt.xlim(np.min(x), np.max(x))\n",
    "plt.ylim(np.min(y), np.max(y))\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "line = slope*np.array(x)+intercept\n",
    "plt.plot(x, line, 'r', label='y={:.2f}x+{:.2f}'.format(slope,intercept))\n",
    "plt.scatter(x,y, color=\"k\", s=3.5)\n",
    "_= plt.title('Exploring relationship btw the prices of a single hot dog and a medium soft drink at all the Major League Baseball stadia')\n",
    "_ = plt.ylabel('Soft drink price')\n",
    "_= plt.xlabel('Hot dog price ')\n",
    "plt.show()\n",
    "pearson_coef, p_value = stats.pearsonr( x,y) #define the columns to perform calculations on\n",
    "print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [1,1.5,2.75,3,3.25,3.5,3.75,3.75,4,4,4.25,4.5,4.5,4.5,4.75,4.75,4.75,5,5,5,5.25,5.25,5.5,5.5,6,6.25]\n",
    "y = [1,1.5,1.5,3,3.25,2.5,4,4.5,4,4.5,5.25,2.75,4.25,4.5,3.25,4.5,4.75,4.75,5,5.25,4.5,4.75,4,5.75,4.5,5]\n",
    "\n",
    "fig = plt.figure(figsize=(2.2,2.2), dpi=400)\n",
    "ax = plt.subplot(111)\n",
    "plt.xlim(np.min(x), np.max(x))\n",
    "plt.ylim(np.min(y), np.max(y))\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x,y)\n",
    "line = slope*np.array(x)+intercept\n",
    "plt.plot(x, line, 'r', label='y={:.2f}x+{:.2f}'.format(slope,intercept))\n",
    "plt.scatter(x,y, color=\"k\", s=3.5)\n",
    "_= plt.title('Exploring relationship btw the prices of a single hot dog and a medium soft drink at all the Major League Baseball stadia')\n",
    "_ = plt.ylabel('Soft drink price')\n",
    "_= plt.xlabel('Hot dog price ')\n",
    "plt.show()\n",
    "pearson_coef, p_value = stats.pearsonr( x,y) #define the columns to perform calculations on\n",
    "print(\"Pearson Correlation Coefficient: \", pearson_coef, \"and a P-value of:\", p_value) # Results \n",
    "def regression_equation(arr_1, arr_2):\n",
    "    \"\"\"The function prepares the regression equation\"\"\"\n",
    "    x_bar = np.mean(arr_1)\n",
    "    y_bar = np.mean(arr_2)\n",
    "    std_x = np.std(arr_1)\n",
    "    std_y = np.std(arr_2)    \n",
    "    pearson_coef, p_value = stats.pearsonr(arr_1, arr_2)\n",
    "    b = pearson_coef * (float(std_y) / float(std_x))\n",
    "    a = y_bar - b * x_bar\n",
    "    return a, b, pearson_coef\n",
    "regression_equation(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr2 = [81,74,62,92,76]\n",
    "arr1 = [89,78,59,98,75.4]\n",
    "def t_statistic_two_sample(arr1, arr2):\n",
    "    '''The function calculates t statistic for two-sample test of hypothesis for dependent samples'''\n",
    "    substr = list(np.array(arr1) - np.array(arr2))\n",
    "    avg = np.mean(substr)\n",
    "    dif_from_mean = (substr - avg)**2\n",
    "    st_dev = (sum(dif_from_mean)/ (len(arr1) - 1))**0.5\n",
    "    t_statistic = avg / (st_dev / (len(arr1))**0.5)\n",
    "    return t_statistic\n",
    "t_statistic_two_sample(arr1, arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting iris dataset\n",
    "iris = datasets.load_iris()\n",
    "x = iris.data[:, :1] \n",
    "\n",
    "def number_of_bins(x):\n",
    "    '''The function calculates the number of bins'''\n",
    "    n_bins = round(np.sqrt(len(x)))\n",
    "    return int(n_bins)\n",
    "\n",
    "number_of_bins(x)\n",
    "sns.set()\n",
    "_ = plt.hist(x, bins = number_of_bins(x))\n",
    "_ = plt.xlabel('Width')\n",
    "_ = plt.ylabel('Count')\n",
    "_ = plt.title('Iris width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "x = iris.data[:, :2] \n",
    "\n",
    "\n",
    "_ = sns.swarmplot(x= iris.data[:, :1] , y= iris.data[:, 1:2] )\n",
    "\n",
    "# Label the axes\n",
    "_ = plt.ylabel('petal length (cm)')\n",
    "_ = plt.xlabel('species')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doing a pareto analysis\n",
    "df = pd.read_csv('./files/2015OnLineCustHist.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cum(data, group, sort):\n",
    "    # The function calculates the cum percentage\n",
    "    cum_sum = data.groupby(group).sum().sort_values(by=sort)\n",
    "    cum_sum['percent'] = cum_sum[sort] / data[sort].sum()\n",
    "    cum_sum['cum_per']= cum_sum['percent'].cumsum()\n",
    "    return cum_sum\n",
    "cum(df, df['CustomerId'], 'SalesValue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a control chart\n",
    "df = pd.read_csv('./files/control_chart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean'] = df.mean(axis = 1)\n",
    "df['max'] = df.iloc[:, 1:3].max(axis = 1)\n",
    "df['min'] = df.iloc[:, 1:3].min(axis = 1)\n",
    "df['range'] = df['max'] - df['min']\n",
    "gl_mean = df['mean'].mean()\n",
    "df.insert(7, 'gl_mean', gl_mean)\n",
    "ucl = df['mean'].mean() + 1.880 * 2.75; ucl\n",
    "lcl = df['mean'].mean() - 1.880 * 2.75; lcl\n",
    "df.insert(8, 'ucl', ucl)\n",
    "df.insert(9, 'lcl', lcl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mean'].plot(marker=\"o\")\n",
    "df['gl_mean'].plot(color='black')\n",
    "df['ucl'].plot(color='r')\n",
    "df['lcl'].plot(color='r')\n",
    "plt.title('Control Chart for Mean Weight')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(np.arange(20), ('1-Jan', '2-Jan', '3-Jan', '4-Jan', '5-Jan', '6-Jan', '7-Jan', '8-Jan', '9-Jan', '10-Jan', \n",
    "                           '11-Jan', '12-Jan', '13-Jan', '14-Jan', '15-Jan', '16-Jan',\n",
    "                          '17-Jan', '18-Jan', '19-Jan', '20-Jan'))\n",
    "plt.xticks(rotation=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rang_mean =  df['range'].mean() \n",
    "df.insert(10, 'df_rang_mean', df_rang_mean)\n",
    "ucl_ran = df['range'].mean() * 3.267 \n",
    "lcl_ran = 0\n",
    "df.insert(11, 'ucl_range', ucl_ran)\n",
    "df.insert(12, 'lcl_ran', lcl_ran)\n",
    "df['range'].plot(marker=\"o\")\n",
    "df['df_rang_mean'].plot(color='black')\n",
    "df['ucl_range'].plot(color='r')\n",
    "df['lcl_ran'].plot(color='r')\n",
    "plt.title('Control Chart for Range Weight')\n",
    "plt.ylabel('Value')\n",
    "plt.xlabel('Date')\n",
    "plt.xticks(np.arange(20), ('1-Jan', '2-Jan', '3-Jan', '4-Jan', '5-Jan', '6-Jan', '7-Jan', '8-Jan', '9-Jan', '10-Jan', \n",
    "                           '11-Jan', '12-Jan', '13-Jan', '14-Jan', '15-Jan', '16-Jan',\n",
    "                          '17-Jan', '18-Jan', '19-Jan', '20-Jan'))\n",
    "plt.xticks(rotation=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating expected monetary value. P(S1) = .30, P(S2) = .50, and P(S3) = .20\n",
    "raw = [{'alternative': 'A1', 'S1': 50, 'S2': 70, 'S3': 100},\n",
    "{'alternative': 'A2', 'S1': 90, 'S2': 40, 'S3': 80},\n",
    "{'alternative': 'A3', 'S1': 70, 'S2': 60, 'S3': 90}        \n",
    "        ]\n",
    "df = pd.DataFrame(raw)\n",
    "prob = [{'S1': 0.3, 'S2': 0.5, 'S3': 0.2}]\n",
    "df_prob = pd.DataFrame(prob)\n",
    "for r in range(len(df)):\n",
    "    df.iloc[:,0:3].multiply(df_prob)\n",
    "\n",
    "for i in range(len(df)): \n",
    "    df2 = (df.iloc[i,:3] * df_prob).sum(axis = 1)\n",
    "    print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple lineare regression\n",
    "df = pd.read_csv('./files/dataset_Facebook.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding categorial values\n",
    "#Selecting only those columns that are of the text format\n",
    "obj_df = df.select_dtypes(include=['object']).copy()\n",
    "obj_df.head()\n",
    "#Applying label encoding\n",
    "df[\"Type\"] = df[\"Type\"].astype('category')\n",
    "df.dtypes\n",
    "df[\"type_category\"] = df[\"Type\"].cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying 'Find and replace'\n",
    "df[\"Type\"].value_counts()\n",
    "cleanup_nums = {\"Type\":     {\"Photo\": 1, \"Status\": 2, \"Link\": 3, \"Video\": 4}}\n",
    "df.replace(cleanup_nums, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying an one-code encoding\n",
    "pd.get_dummies(df, columns=[\"Type\"], prefix=[\"Type\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking for correlvation - visual inspection\n",
    "plt.scatter(df['Type'], df['Total Interactions'], color='red')\n",
    "plt.title('Type Vs Total Interactions', fontsize=14)\n",
    "plt.xlabel('Type', fontsize=14)\n",
    "plt.ylabel('Total Interactions', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    " \n",
    "plt.scatter(df['Category'], df['Total Interactions'], color='green')\n",
    "plt.title('Category Vs Total Interactions', fontsize=14)\n",
    "plt.xlabel('Category', fontsize=14)\n",
    "plt.ylabel('Total Interactions', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple linear regression\n",
    "X = df[['Type','Category']] # here we have 2 variables for multiple regression\n",
    "Y = df['Total Interactions']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "print('Intercept: \\n', regr.intercept_)\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# with statsmodels\n",
    "X = sm.add_constant(X) # adding a constant\n",
    " \n",
    "model = sm.OLS(Y, X).fit()\n",
    "predictions = model.predict(X) \n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)\n",
    "\n",
    "df['predictions'] = predictions\n",
    "\n",
    "#Predicting\n",
    "Type = 1\n",
    "Category = 1\n",
    "print ('Predicted Total Interactions: \\n', regr.predict([[Type, Category]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#An interesting application\n",
    "# tkinter GUI\n",
    "root= tk.Tk() \n",
    " \n",
    "canvas1 = tk.Canvas(root, width = 1200, height = 450)\n",
    "canvas1.pack()\n",
    "\n",
    "# with sklearn\n",
    "Intercept_result = ('Intercept: ', regr.intercept_)\n",
    "label_Intercept = tk.Label(root, text=Intercept_result, justify = 'center')\n",
    "canvas1.create_window(260, 220, window=label_Intercept)\n",
    "\n",
    "# with sklearn\n",
    "Coefficients_result  = ('Coefficients: ', regr.coef_)\n",
    "label_Coefficients = tk.Label(root, text=Coefficients_result, justify = 'center')\n",
    "canvas1.create_window(260, 240, window=label_Coefficients)\n",
    "\n",
    "# with statsmodels\n",
    "print_model = model.summary()\n",
    "label_model = tk.Label(root, text=print_model, justify = 'center', relief = 'solid', bg='LightSkyBlue1')\n",
    "canvas1.create_window(800, 220, window=label_model)\n",
    "\n",
    "\n",
    "# New_Interest_Rate label and input box\n",
    "label1 = tk.Label(root, text='Type Type: ')\n",
    "canvas1.create_window(100, 100, window=label1)\n",
    "\n",
    "entry1 = tk.Entry (root) # create 1st entry box\n",
    "canvas1.create_window(270, 100, window=entry1)\n",
    "\n",
    "# New_Unemployment_Rate label and input box\n",
    "label2 = tk.Label(root, text=' Type Category: ')\n",
    "canvas1.create_window(120, 120, window=label2)\n",
    "\n",
    "entry2 = tk.Entry (root) # create 2nd entry box\n",
    "canvas1.create_window(270, 120, window=entry2)\n",
    "\n",
    "\n",
    "def values(): \n",
    "    global Type #our 1st input variable\n",
    "    Type = float(entry1.get()) \n",
    "    \n",
    "    global Category #our 2nd input variable\n",
    "    Category = float(entry2.get()) \n",
    "    \n",
    "    Prediction_result  = ('Predicted Total Interaction: ', regr.predict([[Type, Category]]))\n",
    "    label_Prediction = tk.Label(root, text= Prediction_result, bg='orange')\n",
    "    canvas1.create_window(260, 280, window=label_Prediction)\n",
    "    \n",
    "button1 = tk.Button (root, text='Predict Total Interactions',command=values, bg='orange') # button to call the 'values' command above \n",
    "canvas1.create_window(270, 150, window=button1)\n",
    " \n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing Multiple Standard Error of Estimate\n",
    "(((df['Total Interactions'] - df['predictions'])**2).sum() / (len(df)- (2 + 1))) * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimating a coef of determination\n",
    "mean = df['Total Interactions'].mean()\n",
    "df.insert(20, 'mean', mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_total = ((df['Total Interactions'] - df['mean']) **2).sum(); ss_total\n",
    "ssr = ((df['predictions'] - df['mean']) **2).sum(); ssr\n",
    "r_sq = ssr / ss_total; r_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using adjusted coef of determination\n",
    "sse = ((df['Total Interactions'] - df['predictions']) **2).sum(); sse\n",
    "r_sq_adj = 1 - ((sse / (500 - 3)) / (ss_total / (500 - 1))); r_sq_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gobal test or testing the multiple regression model\n",
    "#H0: β1 = β2 = 0\n",
    "#H1: Not all the βi’s are 0. If the hypothesis test fails to reject the null hypothesis, it implies the regression coefficients are all zero and, logically, are of no value in estimating the dependent variable (heating cost)\n",
    "F = (ssr / 2) / (sse / (500 - 3)); F\n",
    "#F< critical value of , thus we fail to reject Ho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving as a csv\n",
    "df.to_csv('./files/predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'manufacturer': 'Sharp', 'Screen': 46, 'Price': 736.50 },\n",
    "{'manufacturer': 'Samsung', 'Screen': 52, 'Price': 1150},\n",
    "{'manufacturer': 'Samsung', 'Screen': 46, 'Price': 895}, \n",
    "{'manufacturer': 'Sony', 'Screen': 40, 'Price': 625},\n",
    "{'manufacturer': 'Sharp', 'Screen': 52, 'Price': 773.25 },\n",
    "{'manufacturer': 'Samsung', 'Screen': 46, 'Price': 961.25 },\n",
    "{'manufacturer': 'Samsung', 'Screen': 40, 'Price': 686},\n",
    "{'manufacturer': 'Sharp', 'Screen': 37, 'Price': 574.75 },\n",
    "{'manufacturer': 'Sharp', 'Screen': 46, 'Price': 1000},\n",
    "{'manufacturer': 'Sony', 'Screen': 40, 'Price': 722.25 },\n",
    "{'manufacturer': 'Sony', 'Screen': 52, 'Price': 1307.50 },\n",
    "{'manufacturer': 'Samsung', 'Screen': 52, 'Price': 373.75},\n",
    "{'manufacturer': 'Sharp', 'Screen': 37, 'Price': 657.25 },\n",
    "{'manufacturer': 'Sharp', 'Screen': 32, 'Price': 426.75 },\n",
    "{'manufacturer': 'Sharp', 'Screen': 52, 'Price': 1389},\n",
    "{'manufacturer': 'Samsung', 'Screen': 40, 'Price': 874.75 },\n",
    "{'manufacturer': 'Sharp', 'Screen': 32, 'Price': 517.50 },\n",
    "{'manufacturer': 'Samsung', 'Screen': 52, 'Price': 1475},\n",
    "{'manufacturer': 'Sony', 'Screen': 40, 'Price': 954.25 },\n",
    "{'manufacturer': 'Sony', 'Screen': 52, 'Price': 1551.50 },\n",
    "{'manufacturer': 'Sony', 'Screen': 46, 'Price': 1303},\n",
    "{'manufacturer': 'Sony', 'Screen': 46, 'Price': 1430.50 },\n",
    "{'manufacturer': 'Sony', 'Screen': 52, 'Price': 1717.00}    \n",
    "        ]\n",
    "df = pd.DataFrame(raw)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying a label encoding to convert screen to dummy var\n",
    "df[\"Screen\"] = df[\"Screen\"].astype('category')\n",
    "df.dtypes\n",
    "df[\"screen_category\"] = df[\"Screen\"].cat.codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['screen_category'], df['Price'], color='red')\n",
    "plt.title('Screen size Vs Price', fontsize=14)\n",
    "plt.xlabel('Screen', fontsize=14)\n",
    "plt.ylabel('Price', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple linear regression\n",
    "X = df[['Screen']] # here we have 2 variables for multiple regression\n",
    "Y = df['Price']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "print('Intercept: \\n', regr.intercept_)\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# with statsmodels\n",
    "X = sm.add_constant(X) # adding a constant\n",
    " \n",
    "model = sm.OLS(Y, X).fit()\n",
    "predictions = model.predict(X) \n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding dummy vars with 'Find and replace'\n",
    "cleanup_nums = {\"manufacturer\":     {\"Samsung\": 1, \"Sony\": 2, \"Sharp\": 3}}\n",
    "df.replace(cleanup_nums, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(df['manufacturer'], df['Price'], color='red')\n",
    "plt.title('Manufacturer Vs Price', fontsize=14)\n",
    "plt.xlabel('Manufacturer', fontsize=14)\n",
    "plt.ylabel('Price', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a manufacturer to the equation\n",
    "X = df[['screen_category', 'manufacturer']] # here we have 2 variables for multiple regression\n",
    "Y = df['Price']\n",
    " \n",
    "# with sklearn\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X, Y)\n",
    "\n",
    "print('Intercept: \\n', regr.intercept_)\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# with statsmodels\n",
    "X = sm.add_constant(X) # adding a constant\n",
    " \n",
    "model = sm.OLS(Y, X).fit()\n",
    "predictions = model.predict(X) \n",
    "df['predictions'] = predictions\n",
    " \n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['residuals'] = df['Price'] - df['predictions']\n",
    "plt.scatter(df['predictions'], df['residuals'], color='red')\n",
    "plt.title('Residuals Vs Predictions', fontsize=14)\n",
    "plt.xlabel('Predictions of Price', fontsize=14)\n",
    "plt.ylabel('Residuals', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['residuals'])\n",
    "plt.title('Histogram of residuals')\n",
    "plt.xlabel('Residuals', fontsize=14)\n",
    "plt.ylabel('Freq', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./files/predictions_exer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.7073897937178663"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Non-parametric tests\n",
    "def test_of_hypothesis_one_proportion(p, nu, n):\n",
    "    '''The function estimates test of hypothesis'''\n",
    "    z = float( p - nu ) / float(((float(nu)*(1-float(nu)))/float(n))**0.5)\n",
    "    return float(z)\n",
    "test_of_hypothesis_one_proportion(0.0006, 0.0008, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6925955366146597"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pooled_proportion(x1, x2, n1, n2):\n",
    "    global pc\n",
    "    pc = float((x1 + x2)) / float((n1 + n2))\n",
    "    return pc\n",
    "    \"\"\"The function calculation pooled proportion\"\"\"\n",
    "def test_of_hypothesis_two_proportion(p1, p2, n1, n2, pc):\n",
    "    \"\"\"The function estimates whether \"\"\"\n",
    "    z = float(p1 - p2) / ((pc * (1 - pc)/float(n1)) + (pc * (1 - pc)/float(n2))) ** 0.5\n",
    "    return z\n",
    "test_of_hypothesis_two_proportion(0.33, 0.18, 300, 200, pooled_proportion(100, 36, 300, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi_square(obs_freq, exp_freq):\n",
    "    \"\"\"The function calculates chi-square statistics for data of nomical scale\"\"\"\n",
    "    chi_square = (((obs_freq - exp_freq) ** 2) / exp_freq).sum()\n",
    "    return chi_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'favorite_meal': 'Chicken', 'observed_frequency': 32, 'expected_frequency': 30 },\n",
    "{'favorite_meal': 'Fish', 'observed_frequency': 24, 'expected_frequency': 30},\n",
    "{'favorite_meal': 'Meat', 'observed_frequency': 35, 'expected_frequency': 30}, \n",
    "{'favorite_meal': 'Pasta', 'observed_frequency': 29, 'expected_frequency': 30},   \n",
    "        ]\n",
    "df = pd.DataFrame(raw)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_square(df['observed_frequency'], df['expected_frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.52"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'turn': 'straight', 'observed_frequency': 112, 'expected_frequency': 100 },\n",
    "{'turn': 'left', 'observed_frequency': 48, 'expected_frequency': 50},\n",
    "{'turn': 'right', 'observed_frequency': 40, 'expected_frequency': 50}\n",
    "        ]\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "chi_square(df['observed_frequency'], df['expected_frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.933928571428571"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'region': 'Northeast', 'observed_frequency': 68, 'expected_frequency': 84},\n",
    "{'region': 'Midwest', 'observed_frequency': 104, 'expected_frequency': 96},\n",
    "{'region': 'South', 'observed_frequency': 155, 'expected_frequency': 140},\n",
    "{'region': 'South', 'observed_frequency': 73, 'expected_frequency': 80}       \n",
    "        ]\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "chi_square(df['observed_frequency'], df['expected_frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.879999999999999"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'radio': '1', 'observed_frequency': 53},\n",
    "{'radio': '2', 'observed_frequency': 64},\n",
    "{'radio': '3', 'observed_frequency': 33}\n",
    "        ]\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "def expected_frequency(data, observed):\n",
    "    \"\"\"The function adds the expected frequence\"\"\"\n",
    "    exp = observed.sum() / len(data)\n",
    "    data.insert(data.shape[1], 'expected_frequency', exp)\n",
    "    return data\n",
    "expected_frequency(df, df['observed_frequency'])\n",
    "\n",
    "chi_square(df['observed_frequency'], df['expected_frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>observed_frequency</th>\n",
       "      <th>expected_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category  observed_frequency  expected_frequency\n",
       "0        A                  10                  20\n",
       "1        B                  20                  20\n",
       "2        C                  30                  20"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'category': 'A', 'observed_frequency': 10 },\n",
    "{'category': 'B', 'observed_frequency': 20},\n",
    "{'category': 'C', 'observed_frequency': 30}\n",
    "        ]\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "def expected_frequency(data, observed):\n",
    "    \"\"\"The function adds the expected frequence\"\"\"\n",
    "    exp = observed.sum() / len(data)\n",
    "    data.insert(data.shape[1], 'expected_frequency', exp)\n",
    "    return data\n",
    "expected_frequency(df, df['observed_frequency'])\n",
    "\n",
    "chi_square(df['observed_frequency'], df['expected_frequency'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'outcome': '1', 'observed_frequency': 3 },\n",
    "{'outcome': '2', 'observed_frequency': 6},\n",
    "{'outcome': '3', 'observed_frequency': 2},\n",
    "{'outcome': '4', 'observed_frequency': 3},\n",
    "{'outcome': '5', 'observed_frequency': 9},\n",
    "{'outcome': '6', 'observed_frequency': 7}\n",
    "        ]\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "def expected_frequency(data, observed):\n",
    "    \"\"\"The function adds the expected frequence\"\"\"\n",
    "    exp = observed.sum() / len(data)\n",
    "    data.insert(data.shape[1], 'expected_frequency', exp)\n",
    "    return data\n",
    "expected_frequency(df, df['observed_frequency'])\n",
    "\n",
    "chi_square(df['observed_frequency'], df['expected_frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'category': 'A', 'observed_frequency': 30, 'expected_frequency': 24},\n",
    "{'category': 'B', 'observed_frequency': 20, 'expected_frequency': 24},\n",
    "{'category': 'C', 'observed_frequency': 10, 'expected_frequency': 12}\n",
    "        ]\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "chi_square(df['observed_frequency'], df['expected_frequency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfied</th>\n",
       "      <th>neutral</th>\n",
       "      <th>dissatisfied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>127</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfied  neutral  dissatisfied\n",
       "0         30       17             8\n",
       "1        140      127            58"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'pay type': 'Salary', 'satisfied': 30, 'neutral': 17, 'dissatisfied': 8},\n",
    "{'pay type': 'Hourly', 'satisfied': 140, 'neutral': 127, 'dissatisfied': 58}\n",
    "        ]\n",
    "df = pd.DataFrame(raw)\n",
    "df_dropped = df.drop(['pay type'], axis = 1)\n",
    "new_order = [2, 1, 0]\n",
    "df_dropped = df_dropped[df_dropped.columns[new_order]]; df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfied</th>\n",
       "      <th>neutral</th>\n",
       "      <th>dissatisfied</th>\n",
       "      <th>row_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>127</td>\n",
       "      <td>58</td>\n",
       "      <td>325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_sum</th>\n",
       "      <td>170</td>\n",
       "      <td>144</td>\n",
       "      <td>66</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         satisfied  neutral  dissatisfied  row_sum\n",
       "0               30       17             8       55\n",
       "1              140      127            58      325\n",
       "col_sum        170      144            66      380"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating total row and col sum\n",
    "df_dropped['row_sum'] = df_dropped.sum(axis = 1)\n",
    "df_dropped.loc['col_sum'] = df_dropped.sum()\n",
    "df_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145.39473684210526"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def degree_of_freedom(data):\n",
    "    \"\"\"The function calculates the degrees of freedrom for the further calculation of the critical value of chi-square\"\"\"\n",
    "    df = (len(data) - 1)*(data.shape[1] - 1)\n",
    "    return df\n",
    "#exp_sat = (df.iloc[0, 1:].sum() * df.iloc[:, 1].sum()) / float(df.iloc[:, 1:].sum().sum())\n",
    "#exp_neut = (df.iloc[1, 1:].sum() * df.iloc[:, 1].sum()) / float(df.iloc[:, 1:].sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfied</th>\n",
       "      <th>neutral</th>\n",
       "      <th>dissatisfied</th>\n",
       "      <th>exp_satisfied</th>\n",
       "      <th>exp_neutral</th>\n",
       "      <th>exp_dissatisfied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>24.605263</td>\n",
       "      <td>20.842105</td>\n",
       "      <td>9.552632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>127</td>\n",
       "      <td>58</td>\n",
       "      <td>145.394737</td>\n",
       "      <td>123.157895</td>\n",
       "      <td>56.447368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfied  neutral  dissatisfied  exp_satisfied  exp_neutral  \\\n",
       "0         30       17             8      24.605263    20.842105   \n",
       "1        140      127            58     145.394737   123.157895   \n",
       "\n",
       "   exp_dissatisfied  \n",
       "0          9.552632  \n",
       "1         56.447368  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = df_dropped.loc['col_sum', 'row_sum']\n",
    "arr = np.outer(df_dropped['row_sum'], df_dropped.loc['col_sum']) / float(t)\n",
    "df1 = pd.DataFrame(arr[:2,:3], columns = df_dropped.columns[:-1]).add_prefix('exp_')\n",
    "df = pd.concat([df_dropped.iloc[:-1, :-1], df1], axis = 1); df\n",
    "#Alternatively, expected_values = sm.stats.Table(df_dropped).fittedvalues; expected_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfied</th>\n",
       "      <th>neutral</th>\n",
       "      <th>dissatisfied</th>\n",
       "      <th>exp_satisfied</th>\n",
       "      <th>exp_neutral</th>\n",
       "      <th>exp_dissatisfied</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>8</td>\n",
       "      <td>24.605263</td>\n",
       "      <td>20.842105</td>\n",
       "      <td>9.552632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>140</td>\n",
       "      <td>127</td>\n",
       "      <td>58</td>\n",
       "      <td>145.394737</td>\n",
       "      <td>123.157895</td>\n",
       "      <td>56.447368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   satisfied  neutral  dissatisfied  exp_satisfied  exp_neutral  \\\n",
       "0         30       17             8      24.605263    20.842105   \n",
       "1        140      127            58     145.394737   123.157895   \n",
       "\n",
       "   exp_dissatisfied  \n",
       "0          9.552632  \n",
       "1         56.447368  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Putting the above together as a function\n",
    "def expected_frequency(data):\n",
    "    \"\"\"The function calculates expected frequency\"\"\"\n",
    "    data['row_sum'] = data.sum(axis = 1)\n",
    "    data.loc['col_sum'] = data.sum()\n",
    "    t = data.loc['col_sum', 'row_sum']\n",
    "    arr = np.outer(data['row_sum'], data.loc['col_sum']) / float(t)\n",
    "    data2 = pd.DataFrame(arr[:-1, :-1], columns = data.columns[:-1]).add_prefix('exp_')\n",
    "    data = pd.concat([data.iloc[:-1, :-1], data2], axis = 1)\n",
    "    return data\n",
    "df = expected_frequency(df_dropped); df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.506159912577024"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi = (((df.iloc[:, 0] - df.iloc[:, 3])**2 /  df.iloc[:, 3]) + ((df.iloc[:, 1] - df.iloc[:, 4])**2 /  df.iloc[:, 4]) + ((df.iloc[:, 2] - df.iloc[:, 5])**2 /  df.iloc[:, 5])).sum()\n",
    "chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'reduce the deficit': 244, 'increase the deficit': 194, 'no opinion': 68},\n",
    "{'reduce the deficit': 305, 'increase the deficit': 114, 'no opinion': 25}\n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "\n",
    "def expected_frequency(data):\n",
    "    \"\"\"The function calculates expected frequency\"\"\"\n",
    "    data['row_sum'] = data.sum(axis = 1)\n",
    "    data.loc['col_sum'] = data.sum()\n",
    "    t = data.loc['col_sum', 'row_sum']\n",
    "    arr = np.outer(data['row_sum'], data.loc['col_sum']) / float(t)\n",
    "    data2 = pd.DataFrame(arr[:-1, :-1], columns = data.columns[:-1]).add_prefix('exp_')\n",
    "    data = pd.concat([data.iloc[:-1, :-1], data2], axis = 1)\n",
    "    return data\n",
    "df2 = expected_frequency(df); df2\n",
    "\n",
    "chi = (((df2.iloc[:, 0] - df2.iloc[:, 3])**2 /  df2.iloc[:, 3]) + ((df2.iloc[:, 1] - df2.iloc[:, 4])**2 /  df2.iloc[:, 4]) + ((df2.iloc[:, 2] - df2.iloc[:, 5])**2 /  df2.iloc[:, 5])).sum()\n",
    "chi\n",
    "\n",
    "def degree_of_freedom(data):\n",
    "    \"\"\"The function calculates the degrees of freedrom for the further calculation of the critical value of chi-square\"\"\"\n",
    "    df = (len(data) - 1)*(data.shape[1] - 1)\n",
    "    return df\n",
    "degree_of_freedom(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'name': 'sal', 'age': 28, 'browsing time': 342},\n",
    "{'name': 'ray', 'age': 50, 'browsing time': 125},\n",
    "{'name': 'roberta', 'age': 44, 'browsing time': 121},\n",
    "{'name': 'jose', 'age': 32, 'browsing time': 257},\n",
    "{'name': 'tom', 'age': 55, 'browsing time': 56},\n",
    "{'name': 'george', 'age': 60, 'browsing time': 225},\n",
    "{'name': 'joe', 'age': 38, 'browsing time': 185},\n",
    "{'name': 'jack', 'age': 22, 'browsing time': 141},\n",
    "{'name': 'marty', 'age': 21, 'browsing time': 342},\n",
    "{'name': 'marty', 'age': 45, 'browsing time': 169},\n",
    "{'name': 'joyce', 'age': 52, 'browsing time': 218},\n",
    "{'name': 'bernie', 'age': 33, 'browsing time': 241},\n",
    "{'name': 'judy', 'age': 19, 'browsing time': 583},\n",
    "{'name': 'jody', 'age': 17, 'browsing time': 394},\n",
    "{'name': 'ron', 'age': 21, 'browsing time': 249}       \n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearmans correlation coefficient: -0.727\n",
      "Samples are correlated (reject H0) p=0.002\n"
     ]
    }
   ],
   "source": [
    "#Calculating spearman's correlation\n",
    "coef, p = spearmanr(df['age'], df['browsing time'])\n",
    "print('Spearmans correlation coefficient: %.3f' % coef)\n",
    "\n",
    "# interpret the significance\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Samples are uncorrelated (fail to reject H0) p=%.3f' % p)\n",
    "else:\n",
    "\tprint('Samples are correlated (reject H0) p=%.3f' % p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>822.7</td>\n",
       "      <td>China</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.7</td>\n",
       "      <td>Japan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.2</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>86.5</td>\n",
       "      <td>India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>71.5</td>\n",
       "      <td>Russia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amount        country\n",
       "0   822.7          China\n",
       "1   110.7          Japan\n",
       "2    88.2  United States\n",
       "3    86.5          India\n",
       "4    71.5         Russia"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'country': 'China', 'amount': 822.7},\n",
    "{'country': 'Japan', 'amount': 110.7},\n",
    "{'country': 'United States', 'amount': 88.2},\n",
    "{'country': 'India', 'amount': 86.5},   \n",
    "{'country': 'Russia', 'amount': 71.5}          \n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "932.7664399092971"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a subset i.e. extracting only China and the US as per the task\n",
    "df_subset = df.loc[df['country'].isin(['China','United States'])]\n",
    "\n",
    "#Calculating the index\n",
    "(df_subset.iloc[0,0]/df_subset.iloc[1,0]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69220</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54818</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55177</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65694</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83040</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88378</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>97420</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>98608</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    loan  year\n",
       "0  69220  2008\n",
       "1  54818  2009\n",
       "2  55177  2010\n",
       "3  65694  2011\n",
       "4  83040  2012\n",
       "5  88378  2013\n",
       "6  97420  2014\n",
       "7  98608  2015"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'year': '2008', 'loan': 69220},\n",
    "{'year': '2009', 'loan': 54818},\n",
    "{'year': '2010', 'loan': 55177},\n",
    "{'year': '2011', 'loan': 65694},   \n",
    "{'year': '2012', 'loan': 83040},    \n",
    "{'year': '2013', 'loan': 88378},\n",
    "{'year': '2014', 'loan': 97420},\n",
    "{'year': '2015', 'loan': 98608}        \n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 79.19387460271598, 79.71251083501878, 94.9060965039006, 119.96532793990175, 127.67697197341809, 140.73967061542908, 142.45593759029182]\n"
     ]
    }
   ],
   "source": [
    "p_c_list = []\n",
    "for p in df.iloc[:,0]:\n",
    "    p_comp = (float(p)/ float(df.iloc[0,0]) ) * 100\n",
    "    p_c_list.append(p_comp)\n",
    "print p_c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>486.6</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>506.8</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>522.2</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>574.6</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>580.7</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>568.5</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>581.9</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>496.1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>456.6</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>433.3</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sales  year\n",
       "0  486.6  2006\n",
       "1  506.8  2007\n",
       "2  522.2  2008\n",
       "3  574.6  2009\n",
       "4  580.7  2010\n",
       "5  568.5  2011\n",
       "6  581.9  2012\n",
       "7  496.1  2013\n",
       "8  456.6  2014\n",
       "9  433.3  2015"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'year': '2006', 'sales': 486.6},\n",
    "{'year': '2007', 'sales': 506.8},\n",
    "{'year': '2008', 'sales': 522.2},\n",
    "{'year': '2009', 'sales': 574.6},   \n",
    "{'year': '2010', 'sales': 580.7},     \n",
    "{'year': '2011', 'sales': 568.5},\n",
    "{'year': '2012', 'sales': 581.9},\n",
    "{'year': '2013', 'sales': 496.1},   \n",
    "{'year': '2014', 'sales': 456.6},    \n",
    "{'year': '2015', 'sales': 433.3},         \n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96.31828978622327, 100.31670625494853, 103.3650039588282, 113.73713380839273, 114.944576405384, 112.52969121140141, 115.18210609659538, 98.1987331749802, 90.38004750593825, 85.7680126682502]\n"
     ]
    }
   ],
   "source": [
    "p_c_list = []\n",
    "for p in df.iloc[:,0]:\n",
    "    p_comp = (float(p)/ ((float(df.iloc[0,0] + float(df.iloc[1,0]) + float(df.iloc[2,0] )))/3)) * 100\n",
    "    p_c_list.append(p_comp)\n",
    "print p_c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>p_00</th>\n",
       "      <th>p_17</th>\n",
       "      <th>q_00</th>\n",
       "      <th>q_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>toothpaste</td>\n",
       "      <td>2.49</td>\n",
       "      <td>3.35</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shampoo</td>\n",
       "      <td>3.29</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cough</td>\n",
       "      <td>1.59</td>\n",
       "      <td>4.19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>anti</td>\n",
       "      <td>1.79</td>\n",
       "      <td>2.49</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item  p_00  p_17  q_00  q_17\n",
       "0  toothpaste  2.49  3.35     6     6\n",
       "1     shampoo  3.29  4.49     4     5\n",
       "2       cough  1.59  4.19     2     3\n",
       "3        anti  1.79  2.49     3     4"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'item': 'toothpaste', 'p_00': 2.49, 'q_00': 6, 'p_17': 3.35, 'q_17': 6},\n",
    "{'item': 'shampoo', 'p_00': 3.29, 'q_00': 4, 'p_17': 4.49, 'q_17': 5},\n",
    "{'item': 'cough', 'p_00': 1.59, 'q_00': 2, 'p_17': 4.19, 'q_17': 3},\n",
    "{'item': 'anti', 'p_00': 1.79, 'q_00': 3, 'p_17': 2.49, 'q_17': 4}        \n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    134.538153\n",
       "1    136.474164\n",
       "2    263.522013\n",
       "3    139.106145\n",
       "dtype: float64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determining the simple price indices\n",
    "(df.iloc[:,2]/ df.iloc[:,1]) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    134.538153\n",
       "1    136.474164\n",
       "2    263.522013\n",
       "3    139.106145\n",
       "dtype: float64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_price_index(p0, p1):\n",
    "    \"\"\"The function calculates simple price index\"\"\"\n",
    "    ind = (p1 / p0 ) * 100\n",
    "    return ind\n",
    "simple_price_index(df.iloc[:,1], df.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158.51528384279476"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determining the simple aggregate price index for the two years\n",
    "(df.iloc[:,2].sum()/df.iloc[:,1].sum())*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158.51528384279476"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def simple_aggregate_price_index(p0, p1):\n",
    "    \"\"\"The function calculates aggregate price index\"\"\"\n",
    "    ind = (p1.sum() / p0.sum() ) * 100\n",
    "    return ind\n",
    "simple_aggregate_price_index(df.iloc[:,1], df.iloc[:,2])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147.09413369713508"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determining the index following Laspeyres Price Index\n",
    "laspeyres = ((df.iloc[:,2]*df.iloc[:,3]).sum()/(df.iloc[:,1]*df.iloc[:,3]).sum())*100; laspeyres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147.09413369713508"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def laspeyres(p0, p1, q0):\n",
    "    \"\"\"The function calculates Laspeyres Price Index\"\"\"\n",
    "    ind = ((p1*q0).sum()/(p0*q0).sum())*100\n",
    "    return ind\n",
    "laspeyres(df.iloc[:,1], df.iloc[:,2], df.iloc[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.2308402585411"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determining the index following Paashe price Index\n",
    "paashe = ((df.iloc[:,2]*df.iloc[:,4]).sum()/(df.iloc[:,1]*df.iloc[:,4]).sum())*100; paashe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150.2308402585411"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def paashe(p0, p1, q1):\n",
    "    \"\"\"The function calculates Paashe Price Index\"\"\"\n",
    "    ind = ((p1*q1).sum()/(p0*q1).sum())*100\n",
    "    return ind\n",
    "paashe(df.iloc[:,1], df.iloc[:,2], df.iloc[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148.6542138737506"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Determing the index following Fisher Ideal index\n",
    "fisher = (laspeyres * paashe) ** 0.5; fisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "148.6542138737506"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fisher(laspeyres, paashe):\n",
    "    \"\"\"The function calculates Fisher Ideal Index\"\"\"\n",
    "    ind = (laspeyres * paashe) ** 0.5\n",
    "    return ind\n",
    "fisher(laspeyres(df.iloc[:,1], df.iloc[:,2], df.iloc[:,3]), paashe(df.iloc[:,1], df.iloc[:,2], df.iloc[:,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>p_00</th>\n",
       "      <th>p_17</th>\n",
       "      <th>q_00</th>\n",
       "      <th>q_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oats</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.09</td>\n",
       "      <td>116</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wheat</td>\n",
       "      <td>3.56</td>\n",
       "      <td>5.99</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cern</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.65</td>\n",
       "      <td>8967</td>\n",
       "      <td>13601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barkeley</td>\n",
       "      <td>2.72</td>\n",
       "      <td>5.53</td>\n",
       "      <td>227</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       item  p_00  p_17  q_00   q_17\n",
       "0      oats  1.81  2.09   116     90\n",
       "1     wheat  3.56  5.99     2      2\n",
       "2      cern  2.32  3.65  8967  13601\n",
       "3  barkeley  2.72  5.53   227    214"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'item': 'oats', 'p_00': 1.81, 'q_00': 116, 'p_17': 2.09, 'q_17': 90},\n",
    "{'item': 'wheat', 'p_00': 3.56, 'q_00': 2, 'p_17': 5.99, 'q_17': 2},\n",
    "{'item': 'cern', 'p_00': 2.32, 'q_00': 8967, 'p_17': 3.65, 'q_17': 13601},\n",
    "{'item': 'barkeley', 'p_00': 2.72, 'q_00': 227, 'p_17': 5.53, 'q_17': 214}        \n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235.82236957642957"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def value_index(p0, p1, q0, q1):\n",
    "    \"\"\"The function calculates Value index\"\"\"\n",
    "    ind = ((p1*q1).sum()/(p0*q0).sum())*100\n",
    "    return ind\n",
    "value_index(df.iloc[:,1], df.iloc[:,2], df.iloc[:,3], df.iloc[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indicator</th>\n",
       "      <th>v0</th>\n",
       "      <th>v1</th>\n",
       "      <th>w</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unemployemnt</td>\n",
       "      <td>5.30</td>\n",
       "      <td>6.80</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>county storck</td>\n",
       "      <td>265.88</td>\n",
       "      <td>362.26</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>country_price_index</td>\n",
       "      <td>109.60</td>\n",
       "      <td>125.00</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>retail_sales</td>\n",
       "      <td>529917.00</td>\n",
       "      <td>622864.00</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             indicator         v0         v1     w\n",
       "0         unemployemnt       5.30       6.80  0.20\n",
       "1        county storck     265.88     362.26  0.40\n",
       "2  country_price_index     109.60     125.00  0.25\n",
       "3         retail_sales  529917.00  622864.00  0.15"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'indicator': 'unemployemnt', 'v0': 5.3, 'v1': 6.8, 'w': 0.2},\n",
    "{'indicator': 'county storck', 'v0': 265.88, 'v1': 362.26, 'w': 0.4},\n",
    "{'indicator': 'country_price_index','v0': 109.6, 'v1': 125.0, 'w': 0.25},  \n",
    "{'indicator': 'retail_sales','v0': 529917.0 , 'v1':  622864.0, 'w': 0.15}\n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126.30391290967242"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def special_purpose_index(v0, v1, w):\n",
    "    \"\"\"The function calculates special purpose index\"\"\"\n",
    "    ind = (((v1 / v0 ) * w).sum()) * 100\n",
    "    return ind\n",
    "special_purpose_index(df.iloc[:,1], df.iloc[:,2], df.iloc[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employees</th>\n",
       "      <th>revenue</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>325</td>\n",
       "      <td>134</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>307</td>\n",
       "      <td>152</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316</td>\n",
       "      <td>157</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>319</td>\n",
       "      <td>168</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>327</td>\n",
       "      <td>177</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>323</td>\n",
       "      <td>183</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>304</td>\n",
       "      <td>150</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>287</td>\n",
       "      <td>147</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>301</td>\n",
       "      <td>147</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>307</td>\n",
       "      <td>146</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>305</td>\n",
       "      <td>149</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>333</td>\n",
       "      <td>151</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    employees  revenue  year\n",
       "0         325      134  2004\n",
       "1         307      152  2005\n",
       "2         316      157  2006\n",
       "3         319      168  2007\n",
       "4         327      177  2008\n",
       "5         323      183  2009\n",
       "6         304      150  2010\n",
       "7         287      147  2011\n",
       "8         301      147  2012\n",
       "9         307      146  2013\n",
       "10        305      149  2014\n",
       "11        333      151  2015"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'year': '2004', 'revenue': 134, 'employees': 325},\n",
    "{'year': '2005', 'revenue': 152, 'employees': 307},\n",
    "{'year': '2006','revenue': 157, 'employees': 316},  \n",
    "{'year': '2007','revenue': 168, 'employees':  319},\n",
    "{'year': '2008','revenue': 177, 'employees': 327},  \n",
    "{'year': '2009','revenue': 183, 'employees':  323},       \n",
    "{'year': '2010','revenue': 150, 'employees': 304},  \n",
    "{'year': '2011','revenue': 147, 'employees':  287},\n",
    "{'year': '2012','revenue': 147, 'employees': 301},  \n",
    "{'year': '2013','revenue': 146, 'employees':  307}, \n",
    "{'year': '2014','revenue': 149, 'employees': 305},  \n",
    "{'year': '2015','revenue': 151, 'employees':  333}     \n",
    "      ]\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 94.46153846153847, 97.23076923076923, 98.15384615384616, 100.61538461538461, 99.38461538461539, 93.53846153846153, 88.3076923076923, 92.61538461538461, 94.46153846153847, 93.84615384615384, 102.46153846153847]\n"
     ]
    }
   ],
   "source": [
    "#Calculating simple index for employees\n",
    "p_c_list = []\n",
    "for p in df.iloc[:,0]:\n",
    "    p_comp = (float(p)/ (float(df.iloc[0,0]))) * 100\n",
    "    p_c_list.append(p_comp)\n",
    "print p_c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.0, 113.43283582089552, 117.16417910447761, 125.37313432835822, 132.08955223880596, 136.56716417910448, 111.94029850746267, 109.70149253731343, 109.70149253731343, 108.95522388059702, 111.19402985074626, 112.68656716417911]\n"
     ]
    }
   ],
   "source": [
    "#Calculating simple index for revenue\n",
    "p_c_list = []\n",
    "for p in df.iloc[:,1]:\n",
    "    p_comp = (float(p)/ (float(df.iloc[0,1]))) * 100\n",
    "    p_c_list.append(p_comp)\n",
    "print p_c_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>p_00</th>\n",
       "      <th>p_17</th>\n",
       "      <th>q_00</th>\n",
       "      <th>q_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>margarine</td>\n",
       "      <td>0.81</td>\n",
       "      <td>2.00</td>\n",
       "      <td>18</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shortening</td>\n",
       "      <td>0.84</td>\n",
       "      <td>1.88</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>milk</td>\n",
       "      <td>1.44</td>\n",
       "      <td>2.89</td>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>potato</td>\n",
       "      <td>2.91</td>\n",
       "      <td>3.99</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         item  p_00  p_17  q_00  q_17\n",
       "0   margarine  0.81  2.00    18    27\n",
       "1  shortening  0.84  1.88     5     9\n",
       "2        milk  1.44  2.89    70    65\n",
       "3      potato  2.91  3.99    27    33"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating a dataset\n",
    "raw = [{'item': 'margarine', 'p_00': 0.81, 'q_00': 18, 'p_17': 2, 'q_17': 27},\n",
    "{'item': 'shortening', 'p_00': 0.84, 'q_00': 5, 'p_17': 1.88, 'q_17': 9},\n",
    "{'item': 'milk', 'p_00': 1.44, 'q_00': 70, 'p_17': 2.89, 'q_17': 65},\n",
    "{'item': 'potato', 'p_00': 2.91, 'q_00': 27, 'p_17': 3.99, 'q_17': 33}        \n",
    "        ]\n",
    "\n",
    "df = pd.DataFrame(raw)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    246.913580\n",
       "1    223.809524\n",
       "2    200.694444\n",
       "3    137.113402\n",
       "dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_price_index(df.iloc[:,1], df.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179.3742114559677"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laspeyres(df.iloc[:,1], df.iloc[:,2], df.iloc[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178.80333414690222"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisher(laspeyres(df.iloc[:,1], df.iloc[:,2], df.iloc[:,3]), paashe(df.iloc[:,1], df.iloc[:,2], df.iloc[:,4]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
